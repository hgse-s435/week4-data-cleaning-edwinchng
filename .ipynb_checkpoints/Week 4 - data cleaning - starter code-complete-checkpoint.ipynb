{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the graphs inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This week we are going to work with some text data. In this folder, you should a text file called 'fullpapers.txt'. This file was generated by converting the proceedings of the EDM (Educational Data Mining) conference of 2018. You can find the proceedings here: http://educationaldatamining.org/EDM2017/proc_files/fullpapers.pdf\n",
    "We are going to explore the different terms that are used by authors of the papers in this conference, which will require some data cleaning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is compare the different papers in terms of the vocabulary used. \n",
    "* open the pdf of the proceedings (fullpapers.pdf); \n",
    "* open the txt of the proceedigs (fullpapers.txt)\n",
    "\n",
    "1) we want to split the data into different papers. Brainstorm a few ideas on how to do that:\n",
    "* Split the entire text into pages and then look for the word 'ABSTRACT' to get the page numbers for each paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) First we are going to read the fullpapers.txt file \n",
    "# and assign its content to a variable called \"data\"\n",
    "# hint: https://stackoverflow.com/questions/3758147/easiest-way-to-read-write-a-files-content-in-python\n",
    "with open('./fullpapers.txt') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 3) To facilitate data processing, we want to split this file\n",
    "# into different pages. Create a list called \"pages\" that \n",
    "# stores the text presented on each page of the pdf\n",
    "# Look into the .split() function, what string are we going to want to split by?\n",
    "pages = data.split('Proceedings of the 10th International Conference on Educational Data Mining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) because we don't want to deal with upper case / lower case issues\n",
    "# we are going to lower case everything:\n",
    "# Try using a list comprehension to accomplish this task\n",
    "pages = [x.lower() for x in pages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Now we would like to join pages if they below to the same paper. Can you think of keywords we could like for to decided if the current page is starting a new paper? Write down two ideas:\n",
    "1. Look for the word 'abstract'\n",
    "2. Look for the word 'introduction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) create a new list called \"papers\", which is going to contain \n",
    "# all the papers we have. Iterate through all the pages and \n",
    "# add a new element to the list when you have a full paper\n",
    "# Using a for loop to iterate over all the pages, try to think of a conditional statement to check whether a page\n",
    "# represents a new 'paper'. I.e. what is a common aspect of all papers? \n",
    "papers = []\n",
    "current_paper = ''\n",
    "\n",
    "# iterate through the pages and add each paper to the list \"papers\"\n",
    "for x in pages:\n",
    "    if 'introduction' in x and 'abstract' in x:\n",
    "        if current_paper != '':\n",
    "            papers.append(current_paper)\n",
    "            current_paper = x\n",
    "        else:\n",
    "            current_paper = x\n",
    "    else:\n",
    "        current_paper = current_paper + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "# 7) print how many files you have in the \"papers\" list:\n",
    "print(len(papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- First paper ---\n",
      " \f",
      "zone out no more: mitigating mind wandering during\n",
      "computerized reading\n",
      "sidney k. d’mello, caitlin mills, robert bixler, & nigel bosch\n",
      "university of notre dame\n",
      "118 haggar hall\n",
      "notre dame, in 46556, usa\n",
      "sdmello@nd.edu\n",
      "\n",
      "abstract\n",
      "mind wandering, defined as shifts in attention from task-related\n",
      "process \n",
      "\n",
      "--- Second paper ---\n",
      " \n",
      "\n",
      "15\n",
      "\n",
      "\f",
      "measuring similarity of educational items using data on\n",
      "learners’ performance\n",
      "jiří řihák\n",
      "\n",
      "faculty of informatics\n",
      "masaryk university\n",
      "brno, czech republic\n",
      "\n",
      "thran@mail.muni.cz\n",
      "abstract\n",
      "educational systems typically contain a large pool of items\n",
      "(questions, problems). using data mining techniqu \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8) print the content of the first two paper to make sure it worked\n",
    "# (only print the first 300 characters)\n",
    "print('--- First paper ---\\n',papers[0][:300],'\\n')\n",
    "print('--- Second paper ---\\n',papers[1][:300], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) create a new folder called papers; this is where we are \n",
    "# going to save each paper into a separate text file\n",
    "# hint: google \"how to create a new folder with python\"\n",
    "newpath = './papers'\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) save each paper into its unique file in the \"Papers\" folder\n",
    "# we created above\n",
    "# Hint: \"enumerate\" can provide you with the index of the paper in the list\n",
    "# Feel free to use the following filename for the first paper in the list:\n",
    "# ./Papers/paper0.txt on mac and .\\Papers\\paper0.txt on windows\n",
    "for i, x in enumerate(papers):\n",
    "    file_path = './papers/paper'+ str(i) + '.txt'\n",
    "    f = open(file_path,\"w\")\n",
    "    f.write(x)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might be asking yourself why we need to save the data into text files (instead of just using the list of papers above). One answer is that when we work with large datastsets, it's useful to save snapshots of our data that is \"clean\". This way we don't have to re-run all the code above and we save time. It also allows us to share data between different notebooks for other types of analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) We are going to practice your \"glob\" skills - find all the \n",
    "# text files in the \"Papers\" folder with a glob command!\n",
    "import glob\n",
    "t_files = glob.glob('./papers/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12) iterate through each of the text files and read their contents in the variable below:\n",
    "# Using a for loop, iterate over all the files in the directory, and add them to the list below\n",
    "text_list = []\n",
    "for x in t_files:\n",
    "    with open(x) as f:\n",
    "        paper = f.read()\n",
    "        text_list.append(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13) Now we are going to compute the frequency of each word across all \n",
    "# documents. Feel free to use the link below to help you!\n",
    "# hint: https://www.datacamp.com/community/tutorials/absolute-weighted-word-frequency\n",
    "# (look at the first block of code in the article)\n",
    "# Using the text_list we create in the cell above, iterate over all words and count their frequencies\n",
    "# If uncomfortable with dictionaries, google python dict\n",
    "word_freq = defaultdict(int)\n",
    "for text in text_list:\n",
    "    for word in text.split():\n",
    "        word_freq[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abs_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>5663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>3402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>2704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>2406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>2028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     abs_freq\n",
       "the      5663\n",
       "of       3402\n",
       "and      2704\n",
       "to       2406\n",
       "a        2028"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 14) If you haven't done so already, create a dataframe from the dictionary\n",
    "# and print the head of the dataframe\n",
    "# Just as we did last week with Pandas, we can do this in only a few lines\n",
    "df = pd.DataFrame.from_dict(word_freq, orient='index').sort_values(0, ascending=False).rename(columns={0: 'abs_freq'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's a problem with the dataframe above? Is there data meaningful?\n",
    "\n",
    "The data currently consists a whole bunch of uninteresting words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15) We are going to remove the following stop words, so that we see more interesting \n",
    "# keywors. Feel free to use the list and hint below to help you:\n",
    "# hint: https://stackoverflow.com/questions/43716402/remove-row-index-dataframe-pandas\n",
    "# the .drop() function could prove useful here\n",
    "STOPWORDS = ['a','able','about','across','after','all','almost','also','am','among',\n",
    "             'an','and','any','are','as','at','be','because','been','but','by','can',\n",
    "             'cannot','could','dear','did','do','does','either','else','ever','every',\n",
    "             'for','from','get','got','had','has','have','he','her','hers','him','his',\n",
    "             'how','however','i','if','in','into','is','it','its','just','least','let',\n",
    "             'like','likely','may','me','might','most','must','my','neither','no','nor',\n",
    "           'not','of','off','often','on','only','or','other','our','own','rather','said',\n",
    "             'say','says','she','should','since','so','some','than','that','the','their',\n",
    "             'them','then','there','these','they','this','tis','to','too','twas','us',\n",
    "             'wants','was','we','were','what','when','where','which','while','who',\n",
    "             'whom','why','will','with','would','yet','you','your']\n",
    "\n",
    "for x in STOPWORDS:\n",
    "    if x in df.index:\n",
    "        df.drop(x,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abs_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>students</th>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student</th>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>=</th>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>each</th>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>more</th>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>using</th>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>used</th>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>performance</th>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>between</th>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>based</th>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>different</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educational</th>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results</th>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             abs_freq\n",
       "learning          638\n",
       "data              512\n",
       "students          421\n",
       "student           407\n",
       "=                 393\n",
       "each              350\n",
       "model             345\n",
       "more              310\n",
       "using             278\n",
       "used              258\n",
       "performance       241\n",
       "between           231\n",
       "number            213\n",
       "two               207\n",
       "based             198\n",
       "set               184\n",
       "different         179\n",
       "educational       173\n",
       "models            172\n",
       "results           171"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 16) print the top 20 words of your new dataframe: we can do this with a list slice \n",
    "df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEyCAYAAAD0qxuRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmcXEW5//HPF4hE1rCERYIGEREQEiBIkCCbC4gKKlEQFBBvXFBxuwoqIuCC94dLQAQji6wiwYUoiCiLyCoJCTteVk0uCAEhbLIkPL8/qprpTCbpc/r0zPScfN+v17xm+kyf6pqe7qfrVD1VpYjAzMzqa5nBroCZmfUvB3ozs5pzoDczqzkHejOzmnOgNzOrOQd6M7Oac6A3M6s5B3ozs5pzoDczq7nlBrsCAGuuuWaMHj16sKthZjakzJgx49GIGNnqfl0R6EePHs306dMHuxpmZkOKpH8UuZ+7bszMas6B3sys5hzozcxqriv66M1s6fDiiy8yZ84cnnvuucGuypAyfPhwRo0axbBhw9o634HezAbMnDlzWHnllRk9ejSSBrs6Q0JE8NhjjzFnzhw22GCDtspw142ZDZjnnnuONdZYw0G+BEmsscYala6CHOjNbEA5yJdX9TlzoDczqzn30ZvZoBl92EUdLe+BY/foaHl10ZWBvsg/3/9QM+uklVZaiaeffrrt859//nn22GMPHn30UQ4//HA++MEPdrB21XRloDczG2pmzpzJiy++yKxZsxb53YIFC1h22WUHoVaJ++jNbKmz1157sfXWW7PZZpsxZcqUl49/8YtfZKuttmLXXXdl7ty5ABx//PFsuummbLHFFuyzzz59lvfII4+w//77M2vWLMaOHcu9997L6NGjOfroo5kwYQJTp07l3nvvZbfddmPrrbdmhx124K677gLg/vvvZ7vttmObbbbhiCOOYKWVVur43+tAb2ZLndNOO40ZM2Ywffp0jj/+eB577DGeeeYZttpqK2666SZ23HFHjjrqKACOPfZYZs6cyS233MLJJ5/cZ3lrrbUWp5xyCjvssAOzZs1iww03BNJEp6uvvpp99tmHSZMmccIJJzBjxgyOO+44PvWpTwFw6KGH8slPfpIbb7yRddZZp1/+Xgd6M1vqHH/88YwZM4bx48cze/Zs7r77bpZZZpmX+9X3339/rr76agC22GIL9ttvP84++2yWW65cb3ejvKeffpprr72WiRMnMnbsWD7+8Y/z0EMPAXDNNdew7777AvDhD3+4U3/iQtxHb2ZLlSuvvJI///nPXHfddaywwgrstNNOfU5GauSuX3TRRVx11VVMmzaNY445httvv71wwF9xxRUBeOmllxgxYkSf/ffNj9VfHOjNbNAMRvbcvHnzWG211VhhhRW46667uP7664EUjC+44AL22Wcfzj33XCZMmMBLL73E7Nmz2XnnnZkwYQLnnnsuTz/9NCNGjCj1mKussgobbLABU6dOZeLEiUQEt9xyC2PGjGH77bfnvPPOY//99+ecc87pjz/ZXTdmtnTZbbfdmD9/PltssQVHHHEE48ePB1Lr+/bbb2frrbfm8ssv5xvf+AYLFixg//33Z/PNN2fLLbfk85//fOkg33DOOedw6qmnMmbMGDbbbDMuvPBCACZPnsyJJ57INttsw7x58zr2dzZTRLS+kzQCOAV4IxDAR4G/A78ERgMPAB+IiMeVrkEmA+8EngUOjIibllT+uHHjonmHKefRm9XTnXfeySabbDLY1ehqi8vn7+u5kzQjIsa1KrNoi34ycElEvAEYA9wJHAZcFhEbAZfl2wC7Axvlr0nASQUfw8zM+kHLQC9pFeAtwKkAEfFCRDwB7Amcke92BrBX/nlP4MxIrgdGSFq34zU3MxsEp59+OmPHjl3o65BDDulY+VVm5y5OkcHY1wJzgdMljQFmAIcCa0fEQwAR8ZCktfL91wNmN50/Jx97qGO1NrMhKyKG9AqWBx10EAcddNCAPmaRLvYlKdJ1sxywFXBSRGwJPENPN01f+voPLlJLSZMkTZc0vTEDzczqbfjw4Tz22GOVA9fSpLHxyPDhw9suo0iLfg4wJyJuyLcvIAX6hyWtm1vz6wKPNN1//abzRwEP9lH5KcAUSIOxbdbfzIaQUaNGMWfOHNy4K6exlWC7Wgb6iPiXpNmSNo6IvwO7AnfkrwOAY/P3C/Mp04BPSzoP2BaY1+jiMbOl27Bhw9reDs/aV3TC1GeAcyS9ArgPOIjU7XO+pIOBfwIT830vJqVW3kNKrxzYziwzM1tIoUAfEbOAvnI1d+3jvgF0bgjazMwq8cxYM7Oac6A3M6s5B3ozs5pzoDczqzkHejOzmnOgNzOrOQd6M7Oac6A3M6s5B3ozs5pzoDczqzkHejOzmnOgNzOrOQd6M7Oac6A3M6s5B3ozs5pzoDczqzkHejOzmnOgNzOrOQd6M7Oac6A3M6s5B3ozs5pzoDczqzkHejOzmnOgNzOrueWK3EnSA8BTwAJgfkSMk7Q68EtgNPAA8IGIeFySgMnAO4FngQMj4qbOV33JRh920RJ//8CxewxQTczMBleZFv3OETE2Isbl24cBl0XERsBl+TbA7sBG+WsScFKnKmtmZuVV6brZEzgj/3wGsFfT8TMjuR4YIWndCo9jZmYVFA30AVwqaYakSfnY2hHxEED+vlY+vh4wu+ncOfmYmZkNgkJ99MD2EfGgpLWAP0m6awn3VR/HYpE7pQ+MSQCvfvWrC1bDzMzKKtSij4gH8/dHgN8AbwIebnTJ5O+P5LvPAdZvOn0U8GAfZU6JiHERMW7kyJHt/wVmZrZELQO9pBUlrdz4GXg7cBswDTgg3+0A4ML88zTgI0rGA/MaXTxmZjbwinTdrA38JmVNshxwbkRcIulG4HxJBwP/BCbm+19MSq28h5ReeVDHa21mZoW1DPQRcR8wpo/jjwG79nE8gEM6UjszM6vMM2PNzGrOgd7MrOYc6M3Mas6B3sys5hzozcxqzoHezKzmHOjNzGrOgd7MrOYc6M3Mas6B3sys5hzozcxqzoHezKzmHOjNzGrOgd7MrOYc6M3Mas6B3sys5hzozcxqzoHezKzmHOjNzGrOgd7MrOZabg6+NBt92EVL/P0Dx+4xQDUxM2ufW/RmZjXnQG9mVnOFA72kZSXNlPT7fHsDSTdIulvSLyW9Ih9fPt++J/9+dP9U3czMiijToj8UuLPp9veAH0bERsDjwMH5+MHA4xHxOuCH+X5mZjZICg3GShoF7AF8G/iCJAG7AB/KdzkD+CZwErBn/hngAuDHkhQR0blqDw2tBnPBA7pm1v+Ktuh/BHwZeCnfXgN4IiLm59tzgPXyz+sBswHy7+fl+5uZ2SBoGeglvQt4JCJmNB/u465R4HfN5U6SNF3S9Llz5xaqrJmZlVekRb898B5JDwDnkbpsfgSMkNTo+hkFPJh/ngOsD5B/vyrw796FRsSUiBgXEeNGjhxZ6Y8wM7PFa9lHHxGHA4cDSNoJ+FJE7CdpKrA3KfgfAFyYT5mWb1+Xf3/50tg/3ynu5zezqqrk0X+FNDB7D6kP/tR8/FRgjXz8C8Bh1apoZmZVlFoCISKuBK7MP98HvKmP+zwHTOxA3czMrAM8M9bMrOYc6M3Mas6B3sys5hzozcxqzoHezKzmHOjNzGrOgd7MrOYc6M3Mas6B3sys5hzozcxqzoHezKzmSq11Y0NTqxUwvfqlWb25RW9mVnNu0VshviowG7rcojczqzkHejOzmnOgNzOrOQd6M7Oac6A3M6s5B3ozs5pzoDczqzkHejOzmnOgNzOrOQd6M7Oaa7kEgqThwFXA8vn+F0TEkZI2AM4DVgduAj4cES9IWh44E9gaeAz4YEQ80E/1tyGi1RIK4GUUzPpLkRb988AuETEGGAvsJmk88D3ghxGxEfA4cHC+/8HA4xHxOuCH+X5mZjZIWgb6SJ7ON4flrwB2AS7Ix88A9so/75lvk3+/qyR1rMZmZlZKoT56SctKmgU8AvwJuBd4IiLm57vMAdbLP68HzAbIv58HrNFHmZMkTZc0fe7cudX+CjMzW6xCgT4iFkTEWGAU8CZgk77ulr/31XqPRQ5ETImIcRExbuTIkUXra2ZmJZXKuomIJ4ArgfHACEmNwdxRwIP55znA+gD596sC/+5EZc3MrLyWgV7SSEkj8s+vBN4K3AlcAeyd73YAcGH+eVq+Tf795RGxSIvezMwGRpEdptYFzpC0LOmD4fyI+L2kO4DzJH0LmAmcmu9/KnCWpHtILfl9+qHeZmZWUMtAHxG3AFv2cfw+Un997+PPARM7UjszM6vMM2PNzGrOgd7MrOaK9NGbdQUvo2DWHrfozcxqzoHezKzmHOjNzGrOgd7MrOYc6M3Mas5ZN7ZUaZW546wdqyO36M3Mas6B3sys5hzozcxqzoHezKzmHOjNzGrOWTdmJTlzx4Yat+jNzGrOgd7MrObcdWM2wLzcsg00t+jNzGrOgd7MrOYc6M3Mas6B3sys5hzozcxqrmXWjaT1gTOBdYCXgCkRMVnS6sAvgdHAA8AHIuJxSQImA+8EngUOjIib+qf6ZksnZ+5YGUVa9POBL0bEJsB44BBJmwKHAZdFxEbAZfk2wO7ARvlrEnBSx2ttZmaFtWzRR8RDwEP556ck3QmsB+wJ7JTvdgZwJfCVfPzMiAjgekkjJK2byzGzLuGlHJYepfroJY0GtgRuANZuBO/8fa18t/WA2U2nzcnHzMxsEBQO9JJWAn4FfC4inlzSXfs4Fn2UN0nSdEnT586dW7QaZmZWUqElECQNIwX5cyLi1/nww40uGUnrAo/k43OA9ZtOHwU82LvMiJgCTAEYN27cIh8EZtb93P0zNLRs0ecsmlOBOyPiB02/mgYckH8+ALiw6fhHlIwH5rl/3sxs8BRp0W8PfBi4VdKsfOyrwLHA+ZIOBv4JTMy/u5iUWnkPKb3yoI7W2MzMSimSdXM1ffe7A+zax/0DOKRivczMrEO8TLGZDRpP/BoYXgLBzKzm3KI3syHNmT+tuUVvZlZzbtGb2VKvE1cFVcvoz/EKt+jNzGrOgd7MrOYc6M3Mas6B3sys5hzozcxqzoHezKzmHOjNzGrOgd7MrOYc6M3Mas6B3sys5hzozcxqzoHezKzmHOjNzGrOgd7MrOYc6M3Mas6B3sys5hzozcxqzoHezKzmHOjNzGquZaCXdJqkRyTd1nRsdUl/knR3/r5aPi5Jx0u6R9Itkrbqz8qbmVlrRVr0Pwd263XsMOCyiNgIuCzfBtgd2Ch/TQJO6kw1zcysXS0DfURcBfy71+E9gTPyz2cAezUdPzOS64ERktbtVGXNzKy8dvvo146IhwDy97Xy8fWA2U33m5OPLULSJEnTJU2fO3dum9UwM7NWOj0Yqz6ORV93jIgpETEuIsaNHDmyw9UwM7OGdgP9w40umfz9kXx8DrB+0/1GAQ+2Xz0zM6uq3UA/DTgg/3wAcGHT8Y/k7JvxwLxGF4+ZmQ2O5VrdQdIvgJ2ANSXNAY4EjgXOl3Qw8E9gYr77xcA7gXuAZ4GD+qHOZmZWQstAHxH7LuZXu/Zx3wAOqVopMzPrHM+MNTOrOQd6M7Oac6A3M6s5B3ozs5pzoDczqzkHejOzmnOgNzOrOQd6M7Oac6A3M6s5B3ozs5pzoDczqzkHejOzmnOgNzOrOQd6M7Oac6A3M6s5B3ozs5pzoDczqzkHejOzmnOgNzOrOQd6M7Oac6A3M6s5B3ozs5pzoDczq7l+CfSSdpP0d0n3SDqsPx7DzMyK6Xigl7QscCKwO7ApsK+kTTv9OGZmVkx/tOjfBNwTEfdFxAvAecCe/fA4ZmZWQH8E+vWA2U235+RjZmY2CBQRnS1Qmgi8IyI+lm9/GHhTRHym1/0mAZPyzY2Bvy+h2DWBRytWrS5ldEMduqWMbqhDt5TRDXXoljK6oQ4DVcZrImJky1IioqNfwHbAH5tuHw4cXrHM6R2oVy3K6IY6dEsZ3VCHbimjG+rQLWV0Qx26qYyI6JeumxuBjSRtIOkVwD7AtH54HDMzK2C5ThcYEfMlfRr4I7AscFpE3N7pxzEzs2I6HugBIuJi4OIOFjnFZXRVHbqljG6oQ7eU0Q116JYyuqEO3VRG5wdjzcysu3gJBDOzmnOgNzOrOQf6fiZp+SLHzJZWfo/0v67to5f0vj4OzwNujYhHBro+7ZJ0U0Rs1erYANVlPeA1NA3CR8RVBc5bfUm/j4h/l6jDa4CNIuLPkl4JLBcRT5U4v+3XhaQlPucRcVPReuTyJpD+ltMljQRWioj7S5y/LLA2C/8//lni3D9GxFvL1LmPcsYAO+Sbf42Im0uc25HnsxPvEUmXRcSurY71tzxh9JKIeErS14GtgG+VeC5WBP4TES9Jej3wBuAPEfFilXr1S9ZNhxxMmnx1Rb69E3A98HpJR0fEWa0KkDQ8l7MZMLxxPCI+WrQSkv4H+BbwH+ASYAzwuYg4u8V565CWfnilpC0B5V+tAqxQ9PGbytslIi5vfG/j/O8BHwTuABbkwwG0DPTAjHxf9fG7AF5bsA7/RZoNvTqwITAKOBko82as8rr4fv4+HBgH3Ez6m7YAbgAmFK2EpCNzGRsDpwPDgLOB7Que/xngSOBh4KV8OHJdWoqIBZKelbRqRMwrWu9edTgU+C/g1/nQ2ZKmRMQJBYuo9Hx24j2S3+MrAGtKWq1XGa8qWMbvSM99nyLiPUXKyY6IiKm5EfAO4DjgJGDbgudfBeyQ/5bLgOmk9+1+JeqwqE7MuuqPL+B3wNpNt9cmvSBXB24rWMZU4BjgXuAA4FJgcsl6zMrf3wuckR//5gLnHUAKRk/l742vacD72ng+bmr+3sb5fweWH+T/6SzgFcDMpmO3DsLr4jxg86bbbwR+3sbfol5/yy0lzr8HWKPi83k+8E/gVOD4xleJ828BVmy6vWKZv6Hq87mE98iFRd8jwKHA/cDzwH355/tJHzqfLljGjkv6KvlczMzfvwt8qPlYwfMb7/PPAF8ue/7ivrq5RT86Ih5uuv0I8PqI+Lekopcxr4uIiZL2jIgzJJ1LmshVxrD8/Z3AL/LjtzwpIs4AzpD0/oj4VcnHXJLWD963+0h/y/NtP3D6w/cDNoiIYyS9GlgnIv5WsIjnI+KFxvMnaTmW0JJajE68Lt4QEbc2bkTEbZLGlqzHCxERkgJevuQuYzapy6mKi/JXu0TP1R3553ZeX209n514j0TEZGCypM9E8SuR3mX8pZ3zFuP/JP0UeCvwvTzWUGYsVJK2I73PDs7HKsfpbg70f5X0e1KrHOD9wFX5DfVEwTIab/wnJL0R+BcwumQ9fifpLlLXzadyX+xzJc7/vaQP5cdt7os9umQ92iLpBFIwfRaYJekymoJ9RHy2RHE/IXUz7EK6UnoK+BWwTcHz/yLpq6RL9bcBnyK10MvoxOviTkmnkLpaAtgfuLNkPc7Pb+gRuUvqo8DPSpx/H3ClpItY+P/xg6IF5MbLK4FXR8SSFgVcnNOBGyT9Jt/ei3R1UFbV5/MaSacCr4qI3fP+FdtFROG6RMQJkt7Mou+zM4uWIWkjUkt8Uxbu6i3UNZl9ANgNOC4inpC0LvDfJc4/lLQ+2G8i4nZJr6Wnm7Jt3TwYK9KbeHtSK+Nq4FdRosKSPkYKRJsDPwdWIvWh/bREGcuT+gCfjNQvuiJp0O3hFqc2zr+E1HKbQVPrKSK+v9iT+i7npojYStLMiNiyxHkHLOn3uVXVdh0k3RwRYwqevwyplfJ20v/0j8ApJf+nnXhdDAc+CbwlH7oKOCkiynyAkz+sXv5bIuJPJc49sq/jEXFUiTLeTeoDfkVEbJBb0UdHiT7lPKA6gfQ3XBURM4ue21RGpedT0h9IHzpfi4gx+UpvZkRsXqIOZ5HGfWbRNAZVpiEj6WrSuMkPgXcDB5FiZJ//q17ndiRhQdLEiJja6lhpVft+uvmL1MXQ8liLMhbpE+/r2BLOL9RvXLQetNlfR+p/Xbbp9rLACiXLuCGf16jLyKL1yeedPdiviab6vBLYuML5GwDDe5U3up3/S4U6zABWpc0xD+Bo4G1V6tCJ5xO4MX9v/jtmlSzjTnLDtcrz2fs5JGUiFTn3fhYeI2j+uq9EHSrFm8V9dW0evaT3Sbpb0jxJT0p6StKTJYvpq9/vgoKPv46krckZAZK2yl87US5r5lpJhVsmS/B0/l44FbGXy0hvxoZXAn8uWcbxwG+AtSR9m9Sa/k6REyNiATBSaUXTtnXidSHpPaSW3yX59lhJZVdYnUpPtgykVmThVpek7STdQe7ikDRG0k9K1mF+LJpxU+YS/QFgX2C6pL9J+r6k0rvBdeD5fEbSGuS6SxpP+fGL24B1Sp7T23P5qvNuSZ+W9F5grSInRsQGEfHa/L33V8uuH0m7527W9SQd3/T1c2B+pb+K7u6j/x/g3RFRtu8USW8gpVSuqoXzrlehqe+thXcAB5JSAJv7TZ8CvlqiOhOAAyU1MgNEuqQslEbXEBFvaf7ehuER0fiwICKellQqzTMizpE0g5QOKWCvkv+fB0j9sdOAZ5rKLdwvTYXXRZMjSVteXpkff5ak0SXLWC7SVpnkMl4o+SH2I9JrbFo+/2ZJZf+3t+Xxn2Vz//JngWuLnhwRpwGnKaU5fgD4Ein9deWS9aj6fH6B9DxsKOka0pXi3iXrsCZwh6S/sfCYR5nUyM+RGnGfJY1B7ULKDCosdy22k7DwIOkK7T35e8NTwOfL1KEv3RzoH67wZt4YeBcwgtTX1vAUKW+4pehc1szuFc7tpGckbRV54ka+WvlPkRN79T8+Avyi+XdRfMLUg/lrGcoHk4Yqr4uG+RExTwWyp5ZgrqT3RMQ0gNwSLrWbUETM7lWHBYu772J8BvgaKbD9gjTmcUzRk/MA6qakXP6/koJrqUljWdXnc0PS+2R90vjLtpSPTd9s98EbIuLG/OPTpP75drSVsBBpotrNks6OiMot+N66OdBPl/RL4Lcs/An968Wf8vJ9LgQulLRdRFxXsR6VsmYi4h/qYwZlxTq143PAVEkP5tvrkiZiFNE8YerVwOP55xGkPO4NihQSeaBR0srpZs8VRgltvy6aVGoJZ58AzpH0Y9JzMRv4SInzZ+cskchXAp+lZOZPRDwLfE1pMlxEiRnG2RqksZMngH8Dj7YZZKo+n41JRquR0hK/T7lJRkTEX7TwrOsVSH9bYUozUf+bRWeP71KimG0jJyzkcx8vcqUn6VZ6uq4W+X3ZHoDeujnQr0JKCXx707GgZxZfETMlHUKFmbGkyRuNrJnSOeiqOIOyUyLixtyltTEpMN0VBadVR8QGAJJOBqZF2m8ASbuT3piFKKW4nkWa3ISkR4GPRLmNaTrxuqjUEgaIiHuB8ZJWIg0Clg2ynwAmk2aGziFN5jukTAGStgFOI18dSZoHfDQiZizxxCwi3pvP24TUjXSFpGUjYlSZelD9+WxcyewBnBwRF0r6ZpkKaNFZ1+tRftb11HzOzyh/ddXwotLyFI2gPZKFx3IW511tPl4hXZte2QmSpgJ3AR8iZRjsB9wZEYeWKOO2iHhjhTrMArYkjZw3UhJvqfoJ3WZd3siiOcJl8oxnRMTWvY5Nj4hxBc+/lpRCd0W+vRPwnYh4c9E6dFp+U64YEWUHdJcndTOMZhDmR+Q63AIcEhF/zbcnAD8p+tqS9C7SOjdvAVYDriNlmZxWoU6ln0+leRH/R2o0NLoU/xYF03ZzGbNI4wQ3NL3Pbo1yKZqLvL7LkrQf6Up5K9JM+r2Br0fV9MiKuq5FL+nLEfE/6pnos5AoN8GnEzNjr5W0eTTN/Cup6gzKjshXFjuRAv3FpD7Rq4HCgR54VGmhpuaJMY+VOH/FRpAHiIgriz4fnXxd5NfBJ0itthmkQfsfRMT/K1oG1a/0Xk/qnlg7It4oaQvgPRHxrRLFPNUI8gARcbWkMlcW7yO9HyZHxIO5Xt8rcT75nKrPZ9VJRtCZWde/k/QpUmZZc7dg4UX7qiYs5P9fo96vIPUAPBMRqxQtoy9dF+jp6aec3oGyOjEztmrWTNUZlJ2yN2lBtpkRcZCktYFTSpaxLynDojGT8qp8rKj7JB1B6r6B9EFxf8FzO/m62DQinsytr4uBr5ACVJlAPyoidqtQh5+RgtlPASLilhwwWwZ69awa+bf82voFKTh8kJz5UtDYProxdyc9H2VUej7zWMOvm24/BDxUsg5/UfVZ140Mm+YPmaDAon2dSliIiIWSFCTtRbpSqaTrAn1E/C5/Lzxjcwmm5AGer5PSt1YCjihZRqWsmYg4Lr/wniT1j38jSsyg7KDG0qfzJa1CejGWmdrdaNkcms9/qY3B1I8CR5GyEET6oDiw4GMv8rpQynleqWy3CzBM0jDSlP8fR8SLbWSMVL3SWyEi/tbrcYsOhPaeVd08c7NlK1bSJ0mB8LW5+6dhZeCagnVo1tfzOdB9woeRZl3fCnyc9IFTqiHTGItqU0cSFvqo028lHVahXkAXBvqGfGn7JRbtA205Ai7pC003G2lSJ+bvpbpOOpE1kwP7YAT3ZtMljSBtNjyDlEJ2Q5kClCZ+ncnCg6kHRMRtBYvYkJRCtwzpf7orKQ2t8HhFh7pdTiZdSdxCWifnNZSfoFP1Su9RSRvSM2i3NwVbsRGxc8m69nYu8AfSui7NQeSpMt0UTX5KmiNxMz3PZ9kP37blcYEzImJ/Klwt5w+r5qUcrgR+WiRpoYMJC83zfpYhJXJU/tDs2sFYSTeT3pC914hpmVGgnnVENiblrzZm6b2btJ7Hx0rU4+WsmYh4vaRXAVMjYolZM7362hZRtc+trNz6/RCpFX8mqdXxXBRfebLyYKqkv5M+vG+jKRMhIv5Rog6zImJs7ibYmtxNUGZwWwuvMxOkN9SyEVH4ai8Hs0UU/VuUFquaAryZ1Pq7H9iv5HMxgpTSOZqFG0NlxrH6haTl2kzVbPfx/kiaSPdCyzsvvoxTSH3ijavGDwMLSsaLqgkLpzfdnE/6AP1ZVNxsqWtb9KRJGCe1c2L05GtfCmzVSH3LKVtlR7/fS86ayWU/qJQH3qoOjZS3o0ljA2eRWn370f5koSodA1h0AAANCUlEQVROJE/kiIijlVLxLqX4ypNQYTA1m9vogqmgE90uzV1Ow0ndc2Vz2P8BIGktis+2bj7/PuCt+flbpo30TEjdE9eTuiuKpPD1G0l70CuNmZTpNlAeoPqs6216ZfpcnhucZVRKWIiIdidqLVE3B/rKI+CkVmvzJ/wLlB+MrZo1846IaJ74cZKkG0hT+QdSWxM5eqkymApwZG419V4quUwOfOVul+i1cqik4+i56itEaX2X75N2MXqENMnmTlKwK3L+vaQg/VfSWMUdZR4/Gx4RX2h9t/6VuytWAHYm9YvvDRS+UuyQTsy6XiBpw0hzJBpXXWXz6SslLKjNHe1a6eZA3/YIeJOzSJkJv8nnNnaJKqNq1syC3M1wXq7DvrQ/GaOKdidyNGt7MDU7iLQH5jAW3j6vTKBfnZ7n/wjSG/vKEuf3ZQVKDkyTJgSNB/4cEVtK2plyGUibkmZ+7gAcpzSZ7ebIk5gKOiu/Jn9P+42hTnhzRGyhND/kKEnfp9z/tLKmq/gVI+KZVvdfjP8mTRq7j/T6fg0ll0LoQMLC2yPiy0oLqs0BJpLWo69foM/9yftHRDsZAC+LiG8rrXXd2Pz4oCi53nYHsmY+RJoBOZkU1K7JxwZa75Un9yZlI5VRdTB1TJSYwLIYlbtd1DTdnDRNfiTluxlejIjHJC0jaZmIuELlctAXkNJ/F5A+9B4mXRmU8QIphfFr9Pw9ZRtDndBYM+nZPIb1GG1mmbRLaVemU0mJEq9W2vT84xHxqaJlRMRlSks4NM8eLzVHogMJC23taNeyXl08GHtdRGw32PWok9xqbEzkuKzMRI58fqXBVEk/A34YEe10UyyuzOVJWQ7vKHFO80DqfNJCaaUGDiX9mTRO8F3SyomPkPp4iw5MP0vqW/8B6aqgzMSzRhn3krrkSi2m1mm5O+8E0od+I7vtlDKD2x2oww2kxsu06JkZW2hWu6RdIuLyXhkvLyvTtdiBhIVjSa+r/5Dy50cAv+/V/VtaNwf6o0j9sL+OQahkp7Jm8ih6XzM5y6y30xUkXR0REyqcfyfpqqDSks29ylyNNF1+o3bLaPNxVyRtKdkYYF8VOKdowFZa7XIC6c38AmkRsKsi4rISdZgG7BNpwtGgUdrO8JOkK+cgjTuU3rGrYh1uiIht1cbuZ5KOiogje2W8NESZ92pfj1m0Hk33X42Fd7RbOSL+VfT8vnRl1032BVLO+3xJjTdUDFRaYgezZn7f9PNw0jjBg4u5b7erOphaZSYp0LFul8oa/cC5L7Z0JlH0rLD6BlL30+eAL7Pw5jCtLCDtA3wF7e8D3AlnkJbjPT7f3pfUffGBAaxD26uBRs9WgUdHxELJBZLKdkFVSlhQWnXzEFIiySTSYP/GLBxHSuvaFn23aLQUWh0rUd4ypEv1MkufdgVJZ5MGU2+naTB1IK9OOtHt0qF6fJz0AfMf0nPRaIgU6h+X9CtgLHAPqQX8V9KCXIVbwVrMfsDRmVnlhXWiFduBOqxJGgd7K+l/cSlwaJkuMeU9kXsdK7XQWW6NH0XPnsZXAd+MiEIb1ystwT2DtKrrG/PV0nURMbZoHfrSzS36xpO2EQuvtnjVAFej01kzG5E+rYeiTgymVlJ0PGAAfAnYrEL/+GTgmkhbLAIvjzcUNtABfQlmShofEdcDSNqW9pZSKE3S9yLiK8DOEbFfm2V0Yke6hqoJCxtGxAcl7QsQEf9RB0ZjuzbQS/oYcChpK79ZpFS260hP2kCqlDXTR1//vyi/aFS3uF7Spp0cTB3C7iWti9+uH/VuPZJe372PLZbS8gt9jf8MSNZNUzfaMOAjkv6Zb7+G9uYFtOOdShOUDqf8ZMiGyjvSNTmHPhIWSnght+IbadAb0sbqqL11baAnBfltgOsjYuf8qXvUQFciIh4ASm+Y3HT+YMyC7S8TgANUcf/bmjictLDZDZToH1fan3U98qbzpOcQUuux1B6+pKU5GoaTcq5XX8x9+0O/bpZR0CWkLRxXVNokXvQsLlZoTC86uyNd27O/c8v9ZNLftL6kc0hdQAdWrFP39tFLujEitlHaUGDbiHheeZ2TAa5HpawZSZdFxK6tjg0Fqri+S50obUJ9Nb2WH2jVnZL71Q8kBenmJZefJC3MVWmiUdXMqKFG0vI5NlwYEW03yHJZw0krYLa9I52kXUndu20lLCitZf92Ug+GSA3dyumz3dyin6O0aNNvgT9JepzByVZpK2smv2hWANbMYw3NLbdXdbqSA2FpDOhLMD/aWH4gOrfpPOpZlx56Vjqs0xVkEY3urk6slnkWaUe6d9C0I13JMqrO/r4eeG1EXFTycZeoa1v0zSTtSMpTviQqrE7XoboUypqRdCgpZe5VpG3SGpeUTwFTIuLEJZxuXU5pdvE/SKmVpZcfyF043wZeFRG7S9oU2C4iTi1RhyvoudpsrHR4XET8b9EyhjpJt5FmB3+DPnalKjnZaWak5SxuibSkwzDgj2Uy5FRy+8I+zr8DeD3ptfUMHeoe7eYWPVp0Hfj1KLeIVn8olDUTEZOByZK+QRp4ezLn125FaoXY0NYYkD+86ViZ5QdOz19fy7f/F/glaRp/Ubuz6L61+zAI8woG0SdILe/eA6lQfh2lTuxIVzVhodJGR4vTtYFeTevAk94Qw0gL+yxxHfh+qEfVrJm9Iy0LPAF4G2nFw5NIC1rZEKTOrMW0ZkScL+lwgIiYL6ls2u5vgSdIS2gP2CzUbhIRVwNXK635XuZDsi997Uj3jZJlVEpY6K/u0a4N9LS5DnyndSBrpvHm3QM4OSIuVFoX34aoSFsyHgdUWYvpGUlr0JNGN57yu1xV3bd2yFNepwZ4XH2sVVOm6yYiGlsPXkX7C8N15f9jmcGuwBK8EGkAod114DtC0iJrj/R1bAn+T2mZ4w8AF+dJMd38vFsxl0p6f4XJLF8gtRpfK+ka0pIBnylZxrVKqyUuzRrb/r2blO7Z+3thkr6TE0Aat1eT1HKz9mYR8Y++vsqU0R+6djBW0pdI/eFvI60Q+FHg3Ig4YYAev5E1cwWwEwtnzfwhIjYpWM4KpE/5WyPibknrAptHxKWdr7UNlNyltyLpiu0/lFyLKb++Pk3K8HiKNG5zQsklEO4AXkcHF4kbaiR9kaa8eXrepwHldphS04JoTccWWRZhKOrarpuovg58VR+nJ2tmBgtnzfy4aCGRVhb8ddPthyi4CbR1rw506Z1Jem1/J9/el5TeN7FEGf0ycDfErJS/N/aHvpD0Xn03qQumjGUbefnw8qqcpZal6FZd26LvFovJmjkmIm4a5KrZIFPaTrDRdXBlRBReYbAbFgKrE6X9od8fPftDrwxMLTOGIenLwHtIyR9B6kWYFhEDve1nx3VdX7GkpyQ92cfXU3mK80DbOwf5RtbMz0lZM7YUU9og4lDSmi53kLaPO7ZEETPzAGyjvAFbCKymKu8PnQP6t4FNSLNjj6lDkAe36FtqmkTxXVI/+7l99eXZ0kXSLcDYiHgp314WmNmqf7zXQmAbAwstBBYFdkSyRUn6GinhoXl/6F9GxHcHtWJdomv76LtII2vmrcD3nDVjTUYAjZmwqxY8pxsWAqud6MD+0L3mzLyC9GH8TNEB9m7mFn0LzpqxviitF34sKStLpL76wyPivEGtmHWMpL2AN0XEVwe7LlU50JuVIGn7iLgmX9mtTsr0EGl3qEr7elr3kXR9RIxvfc/u5kBvVoLy1nJ1ya+2Hr1m1jZWA90xIqrMgO4K7qM3K+fFvEfBKEnH9/5lq41HrKs1L4rWWA200hr33cKB3qycd5EG5nchTaSzmoiIgwa7Dv3Fgd6shIh4VNJU0jry3bI5t1Ug6QT62EWuoQ5XaU4TNCspIhaw6NrnNnRNJ12dDSfNfL87f42lZ/XZIc2DsWZtyDtMrUraLOSZxnEvjTF05R273h4RL+bbw4BLI2Lnwa1Zde66MWvPm/P35t2cgtR3b0PTq0h77jYmwa3EEN3fuTcHerM21KGVZ4s4FrhJ0pX59o7ANwetNh3kPnqzNkhaW9Kpedo9kjaVdPBg18sq+Tlp68AtSEuL7wjcOZgV6hQHerP2/Bz4Iz2X9v9L2r/Ahq6fkPZyfmVETCPtPXHi4FapMxzozdqzZkScD7wEaXNvapKhsRTbNiIOIW+0HhGPkxY3G/Ic6M3a04nNva27vJiXm278T0eSP8iHOg/GmrWn9+beI4G9B7dKVtHxpPXs18rps3sDXx/cKnWGA71Ze+4gBYVnSX25vyX109sQFRHnSJoB7EpakXSviKjFYKwnTJm1QdL5pM29z8mH9gVWi4gym3ubDQgHerM2eHNvG0o8GGvWHm/ubUOGW/RmbZB0Jz2bewO8mjS55iUgWm0SbjaQHOjN2iDpNUv6fUT8Y6DqYtaKA72ZWc25j97MrOYc6M3Mas6B3sys5hzozcxqzoHezKzm/j/W7rASSJjZwQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 17 plot the top 20 results above as a histogram: \n",
    "df[:20].plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you tell from this historgram? What do EDM researchers seem to care about?\n",
    "\n",
    "There is a much apperance of the words 'learning' and 'data'. In other words, EDM researchers seem to care about the use of data to inform learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are improvements you could add to our data cleaning process? Write at least three things:\n",
    "\n",
    "- The references at the end of each paper could have been removed so that they do not contribute to the word count.\n",
    "- Symbols like '=' and numbers like 'two' could also have been included in the list of stopwords.\n",
    "- Similar words like 'student' and 'students' could have been grouped together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count word frequencies per paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the previous section gave us an overall description of the word frequency for all the papers, it would be interesting to look at each individual paper. This is what we are going to do below, by focusing on the top 30 terms used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18) save the top 30 words from the dataframe above \n",
    "# in a new variable called \"top_words\"\n",
    "top_words = df[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19) We are now going to construct a new dataframe where each row is a paper, \n",
    "# each column is one of the top 30 words used and each cell is a count of this word. \n",
    "# NOTE: make sure you add another field called \"text\" where you're going to store the \n",
    "# actual text of the paper. \n",
    "# Hint: build a list of dataframes (one for each papers), \n",
    "# and use the concat function from pandas to concatenate them!\n",
    "d = []\n",
    "dic={}\n",
    "paper_word_freq = defaultdict(int)\n",
    "\n",
    "for i, text in enumerate(text_list):\n",
    "    dic[str(i)]=text\n",
    "    # iterate through the top words, add counts to the dictionary\n",
    "    for word in text.split():\n",
    "        if word in top_words.index:\n",
    "            paper_word_freq[word]+=1\n",
    "    \n",
    "    df_t = pd.DataFrame.from_dict(paper_word_freq, orient='index').rename(columns={0: str(i)})\n",
    "    df_t = df_t.T\n",
    "    # and append the results to the list above (d)\n",
    "    d.append(df_t)\n",
    "    paper_word_freq = paper_word_freq.fromkeys(paper_word_freq, 0)\n",
    "\n",
    "# concatenate the list d into a dataframe\n",
    "df_concatenated = pd.concat(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 20) create a scatter plot of the words 'learning' and 'data'\n",
    "# what can you say from it?\n",
    "df_concatenated.plot(x='learning',y='data',kind='scatter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 21) annotate each point with the index number of the dataframe\n",
    "# hint: https://www.pythonmembers.club/2018/05/08/matplotlib-scatter-plot-annotate-set-text-at-label-each-point/\n",
    "# plt.txt( ) is going to be helpful for us here\n",
    "\n",
    "for i in range(0,17):\n",
    "    x = df_concatenated['learning'][i]\n",
    "    y = df_concatenated['data'][i]\n",
    "    plt.scatter(x, y, marker='x', color='red')\n",
    "    plt.text(x+3, y-1, str(i), fontsize=9)\n",
    "    \n",
    "plt.xlabel('learning')\n",
    "plt.ylabel('data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Paper with highest frequency of \"learning\"---\n",
      " \n",
      "\n",
      "55\n",
      "\n",
      "\f",
      "toward the automatic labeling of course questions for\n",
      "ensuring their alignment with learning outcomes\n",
      "s. supraja\n",
      " \n",
      "\n",
      "--- Paper with highest frequency of \"data\" ---\n",
      " \n",
      "\n",
      "71\n",
      "\n",
      "\f",
      "efficient feature embeddings for student classification\n",
      "with variational auto-encoders\n",
      "severin klingler \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 22) what are the two extreme papers, \n",
    "# i.e., papers with more occurences for each term on each axis?\n",
    "\n",
    "print('--- Paper with highest frequency of \"learning\"---\\n',dic['5'][:120],'\\n')\n",
    "print('--- Paper with highest frequency of \"data\" ---\\n',dic['16'][:110], '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 23) plot the histogram of the paper that had high counts of \"data\"\n",
    "# hint: https://stackoverflow.com/questions/52392728/create-a-histogram-based-on-one-row-of-a-dataframe\n",
    "# .loc is going to be helpful here\n",
    "\n",
    "df_concatenated.iloc[16].plot.bar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 24) plot the histogram of the paper that had high counts of \"learning\"\n",
    "# .loc is going to be helpful here\n",
    "\n",
    "df_concatenated.iloc[5].plot.bar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each paper, there is only one word with a very high count and the rest of the words have a relatively low word count\n"
     ]
    }
   ],
   "source": [
    "# 25) what can you observe? \n",
    "print('For each paper, there is only one word with a very high count and the rest of the words have a relatively low word count') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Paper with highest frequency of \"learning\"---\n",
      " \n",
      "\n",
      "55\n",
      "\n",
      "\f",
      "toward the automatic labeling of course questions for\n",
      "ensuring their alignment with learning outcomes\n",
      "s. supraja\n",
      "\n",
      "kevin hartman\n",
      "\n",
      "sivanagaraja tatinati\n",
      "\n",
      "andy w. h. khong\n",
      "\n",
      "nanyang technological\n",
      "university\n",
      "50 nanyang ave\n",
      "singapore 639798\n",
      "ssupraja001@e.ntu.edu.sg\n",
      "\n",
      "nanyang technological\n",
      "university\n",
      "50 nanyang ave\n",
      "singapore 639798\n",
      "khartman@ntu.edu.sg\n",
      "\n",
      "nanyang technological\n",
      "university\n",
      "50 nanyang ave\n",
      "singapore 639798\n",
      "tatinati@ntu.edu.sg\n",
      "\n",
      "nanyang technological\n",
      "university\n",
      "50 nanyang ave\n",
      "singapore 639798\n",
      "andykhong@ntu.edu.sg\n",
      "\n",
      "abstract\n",
      "expertise in a domain of knowledge is characterized by a greater\n",
      "fluency for solving problems within that domain and a greater\n",
      "facility for transferring the structure of that knowledge to other\n",
      "domains. deliberate practice and the feedback that takes place\n",
      "during practice activities serve as gateways for developing domain\n",
      "expertise. however, there is a difficulty in consistently aligning\n",
      "feedback about a learner’s practice performance with the intended\n",
      "learnin \n",
      "\n",
      "--- Paper with highest frequency of \"data\" ---\n",
      " \n",
      "\n",
      "71\n",
      "\n",
      "\f",
      "efficient feature embeddings for student classification\n",
      "with variational auto-encoders\n",
      "severin klingler\n",
      "\n",
      "dept. of computer science\n",
      "eth zurich, switzerland\n",
      "\n",
      "kseverin@inf.ethz.ch\n",
      "\n",
      "rafael wampfler\n",
      "\n",
      "dept. of computer science\n",
      "eth zurich, switzerland\n",
      "\n",
      "wrafael@inf.ethz.ch\n",
      "\n",
      "barbara solenthaler\n",
      "\n",
      "dept. of computer science\n",
      "eth zurich, switzerland\n",
      "\n",
      "sobarbar@inf.ethz.ch\n",
      "\n",
      "abstract\n",
      "gathering labeled data in educational data mining (edm)\n",
      "is a time and cost intensive task. however, the amount\n",
      "of available training data directly influences the quality of\n",
      "predictive models. unlabeled data, on the other hand, is\n",
      "readily available in high volumes from intelligent tutoring\n",
      "systems and massive open online courses. in this paper, we\n",
      "present a semi-supervised classification pipeline that makes\n",
      "effective use of this unlabeled data to significantly improve\n",
      "model quality. we employ deep variational auto-encoders\n",
      "to learn efficient feature embeddings that improve the performance for standard classifiers by  \n",
      "\n",
      "My interpretation is confirmed as the focus for paper 5 is \"learning outcomes\" while the focus for paper 16 is \"educational data mining\"\n"
     ]
    }
   ],
   "source": [
    "# 26) print the first 1000 characters of each paper. \n",
    "\n",
    "print('--- Paper with highest frequency of \"learning\"---\\n',dic['5'][:1000],'\\n')\n",
    "print('--- Paper with highest frequency of \"data\" ---\\n',dic['16'][:1000], '\\n')\n",
    "\n",
    "# Is your interpretation confirmed?\n",
    "print('My interpretation is confirmed as the focus for paper 5 is \"learning outcomes\" while the focus for paper 16 is \"educational data mining\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are going to work with Regex formulas to extract part of the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27) we are going to work on the first paper to make sure that our \n",
    "# regex works. Just retrieve the text and assign it to a variable below\n",
    "\n",
    "with open('./papers/paper0.txt') as f:\n",
    "    first_paper = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 28) find the text between the words 'abstract' and \n",
    "# 'introduction' for the first paper using a regex\n",
    "# https://stackoverflow.com/questions/12736074/regex-matching-between-two-strings/12736203\n",
    "\n",
    "abstract = re.findall ('abstract(.*\\n?)introduction',first_paper,re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29) find the text between the words 'abstract' and \n",
    "# 'introduction' for the first paper using the .index() function\n",
    "start = first_paper.index('abstract') + 8\n",
    "end = first_paper.index('introduction')\n",
    "abstract_1 = first_paper[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30) add a new column namd \"abstract\" to the dataframe above \n",
    "# and initialize it with an empty string\n",
    "df_concatenated['abstract'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# now add the abstracts to each row of the dataframe using either\n",
    "# of the two methods above\n",
    "# Hint: https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas\n",
    "\n",
    "for i in df_concatenated.index:\n",
    "    t = dic[str(i)]\n",
    "    df_concatenated.at[i,'abstract'] = re.findall('abstract(.*\\n?)introduction', t ,re.DOTALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nthis study investigates a possible way to analyze chat data from\\ncollaborative learning environments using epistemic network\\nanalysis and topic modeling. a 300-topic general topic model\\nbuilt from tasa (touchstone applied science associates) corpus was used in this study. 300 topic scores for each of the 15,670\\nutterances in our chat data were computed. seven relevant topics\\nwere selected based on the total document scores. while the aggregated topic scores had some power in predicting students’\\nlearning, using epistemic network analysis enables assessing the\\ndata from a different angle. the results showed that the topic\\nscore based epistemic networks between low gain students and\\nhigh gain students were significantly different (𝑡 = 2.00). overall,\\nthe results suggest these two analytical approaches provide complementary information and afford new insights into the processes\\nrelated to successful collaborative interactions.\\n\\nkeywords\\nchat; collaborative learning; topic modeling; epistemic network\\nanalysis\\n\\n1. ']\n",
      "['\\nthere is a critical need to develop new educational technology applications that analyze the data collected by universities to ensure that students graduate in a timely fashion\\n(4 to 6 years); and they are well prepared for jobs in their\\nrespective fields of study. in this paper, we present a novel\\napproach for analyzing historical educational records from\\na large, public university to perform next-term grade prediction; i.e., to estimate the grades that a student will get\\nin a course that he/she will enroll in the next term. accurate next-term grade prediction holds the promise for better student degree planning, personalized advising and automated interventions to ensure that students stay on track\\nin their chosen degree program and graduate on time. we\\npresent a factorization-based approach called matrix factorization with temporal course-wise influence that incorporates course-wise influence effects and temporal effects for\\ngrade prediction. in this model, students and courses are\\nrepresented in a latent “knowledge” space. the grade of a\\nstudent on a course is modeled as the similarity of their latent representation in the “knowledge” space. course-wise\\ninfluence is considered as an additional factor in the grade\\nprediction. our experimental results show that the proposed\\nmethod outperforms several baseline approaches and infer\\nmeaningful patterns between pairs of courses within academic programs.\\n\\nkeywords\\nnext-term grade prediction, course-wise influence, temporal\\neffect, latent factor\\n\\n1. ']\n",
      "['\\nreplayability has long been touted as a benefit of educational games. however, little research has measured its impact on learning, or investigated when students choose to replay prior content. in this study, we analyzed data on a sample of 4,827 3rd-5th graders from st math, a game-based educational platform integrated into classroom instruction in\\nover 3,000 classrooms across the u.s. we identified features\\nthat describe elective replays relative to prior gameplay performance, and associated elective replays with in-game accuracy, confidence, and general math ability assessments outside of the games. we found some elective replay patterns\\nwere associated with learning, whereas others indicated that\\nstudents were struggling in the current educational content.\\nwe suggest, therefore, that educational games should use\\nelective replay behaviors to target interventions according\\nto when and whether replay is helpful for learning.\\n\\nkeywords\\neducational games, serious game analytics, replayability\\n\\n1. ']\n",
      "['\\nin this study, we applied decision trees (dt) to extract\\na compact set of pedagogical decision-making rules from\\nan original full set of 3,702 reinforcement learning (rl)induced rules, referred to as the dt-rl rules and full-rl\\nrules respectively. we then evaluated the effectiveness of\\nthe two rule sets against a baseline random condition in\\nwhich the tutor made random yet reasonable decisions. we\\nexplored two types of trees (weighted and unweighted) as\\nwell as two pruning strategies (pre- and post-pruning). we\\nfound that post-pruned weighted trees produced the best results with 529 dt-rl rules. the empirical evaluation was\\nconducted in a classroom study using an existing intelligent\\ntutoring system (its) named pyrenees. 153 students were\\nrandomly assigned to three conditions. the procedure was\\nthe same for all students with domain content and required\\nsteps strictly controlled. the only substantive differences\\nbetween the three conditions were the policy: (full-rl vs.\\ndt-rl vs. random). our result showed that as expected\\nthe machine induced policies (full-rl and dt-rl) are significantly more effective than the random policy; more importantly, no significant difference was found between the\\nfull-rl and dt-rl policies though the number of dt-rl\\nrules is less than 15% of the number of the full-rl rules\\nand the former group also took significantly less time than\\nthe latter.\\n\\n1.\\n\\nintroduction\\n\\nintelligent tutoring systems (itss) are interactive e-learning\\nenvironments that support students’ learning by providing\\ninstruction, scaffolded practice, and on-demand help. the\\nsystem’s behaviors can be viewed as a sequential decisionmaking process where at each step the system chooses an\\nappropriate action from a set of options. pedagogical strategies are the policies used to decide what action to take next\\nin the face of alternatives. each system decision will affect\\nthe user’s subsequent actions and performance. its impact\\non outcomes cannot always be immediately observed and the\\neffectiveness of each decision depends upon the effectiveness\\n\\nof subsequent actions. ideally, an effective learning environment will adapt its decisions to users’ specific needs [1, 11].\\nhowever, there is no existing well-established theory on how\\nto make these system decisions effectively. generally speaking, prior research on pedagogical policies can be divided\\ninto two general categories: top-down or theory-driven, and\\nbottom-up or data-driven.\\nin theory-driven approaches, itss employ hand-coded pedagogical rules that seek to implement existing cognitive or\\nlearning theories [1, 10, 17]. while existing learning literature gives helpful guidance on the design of pedagogical\\nrules, such guidance is often too general to implement as\\neffective immediate decisions. for example, the aptitudetreatment interaction (ati) theory states that instructors\\nshould match their interventions to the aptitude of the learner\\n[5]. while the principle behind this theory is understandable, it is not clear how to implement that rule for each\\ndecision. how do we represent learner’s aptitude for each\\nequation, how exact should be the system’s adaptation, and\\nso on.\\ndata-driven approaches, on the other hand, derive pedagogical policies directly from prior data. here the policies\\nspecify the pedagogical decisions at a detailed level. reinforcement learning (rl), which we use here, is one popular\\napproach that is able to derive pedagogical policies directly\\nfrom student-system interaction logs. these policies are defined as a set of state-action mapping rules, which give the\\nbest decision to take in each state. the states are typically\\nrepresented as sets of features and the actions are pedagogical actions such as presenting a worked example (we) or\\nrequiring the student to solve problems (ps). when the system presents a worked example, the students will be given a\\ndetailed example showing a complete expert solution for the\\nproblem or the best step to take given their current solution\\nstate. in problem solving, by contrast, students are tasked\\nwith solving a problem using the its or with completing an\\nindividual problem-solving step.\\nfor this project, our original complete rl-induced policy involves the following seven features representing the students’\\nlearning process from different perspectives1 .\\n\\n1\\nin the format of: [feature-name] (discretization procedure): explanation of the feature.\\n\\n\\n\\n112\\n\\n\\x0c1. [nwesinceps] (0 → 0; (0, 1] → 1; (1, +∞) → 2):\\nthe number of worked example (we) steps received\\nsince the last problem solving (ps) step.\\n2. [timeinsession] ([0, 2290] → 0; (2290, 4775] → 1;\\n(4775, 7939] → 2; (7939, +∞) → 3): the total time\\nspent in the current session.\\n3. [avgtimeonstepps] ([0, 29.01] → 0; (29.01,\\n48.71] → 1; (48.71, +∞) → 2): the average amount of\\ntime spent on each ps step.\\n4. [avgtimeonstepsessionps] ([0, 23.51] → 0;\\n(23.51, 36.56] → 1; (36.56, 55] → 2; (55, +∞) → 3):\\nthe average amount of time spent on each ps step in\\nthe current session.\\n5. [nstepsincelastwrongkc] ([0, 1] → 0; (1, 7]\\n→ 1; (7, 25] → 2; (25, +∞) → 3): the number of steps\\nreceived since the last wrong ps step on the current\\nknowledge component (kc).\\n6. [nwestepsincelastwrong] ([0, 1] → 0; (1, 4]\\n→ 1; (4, 10] → 2; (10, +∞) → 3): the number of we\\nsteps since the last wrong ps step.\\n7. [ncorrectpsstepsincelastwrongkcsession]\\n(0 → 0; (0, 3] → 1; (3, 10] → 2; (10, +∞) → 3): the\\nnumber of correct ps steps since the last wrong ps\\nstep on the current kc in the current session.\\nwith this feature set, a state can be represented as a 7dimensional vector where each element denotes a discretized\\nfeature value. then, the rules can then be represented as:\\n(0:0:0:0:0:0:0) -> ps\\n(0:0:0:0:0:0:1) -> ps\\n(0:0:0:0:0:1:0) -> ps\\n(0:0:0:0:0:1:1) -> we\\nin this study we discretized the features into three-four values producing a seven-feature state. this results in a state\\nspace of 32 ∗ 45 = 9216, that is 9216 rules in one rl-induced\\npolicy. while these types of polices can specify the exact\\naction to take in each case, they are usually too narrow to\\nbe aligned to existing learning theories. each of the rules\\ncovers only a very specific case and the relationship between\\nrules is unknown. thus it is impossible to explain the power\\nof those rules from the perspective of learning theory. the\\nopacity of those induced rules not only hinders us in improving data-driven methodologies when they go wrong, it also\\nprevents us from advancing learning science research more\\ngenerally. moreover, it is possible that some of the decisions\\nare environment-specific and may not generalize to other\\ncontexts. this in turn prevents translating these induced\\npolicies to environments other than the one from which they\\nare induced. therefore, a general method is needed to shed\\nsome light on the extracted detailed data-driven policies.\\ndecision tree (dt) induction is a robust data mining approach which can be used to extract a compact set of rules\\nfrom a set of specific examples. it builds a tree-like hierarchical decision-making pattern which represents the knowledge it learned. each path from root to leaf represents a\\nsingle rule which may be dealt with separately. prior studies have shown that dts can match training examples in\\nmost cases, even with relatively small trees. davidson et\\n\\nal., for example, built a dt for predicting the extinction\\nrisk of mammals [6]. each of the species was described by\\n11 ecological features (e.g body mass, geographic range and\\npopulation density) and were labeled with their extinction\\nrisk (threatened vs. non-threatened). their tree contained\\n20 general rules which covered 4500 training examples, with\\na decision accuracy over 80%. additionally, reinchard et al.\\nbuilt a dt for predicting the invasiveness of woody plants\\n[13]. the resulting dt encoded 15 rules from 235 examples,\\nwith a decision accuracy over 76%. therefore, in our study,\\nwe will apply dt to extract general pedagogical decisionmaking rules from the detailed rl-induced policies.\\nin short, our primary research question is: is dt an effective methodology for extracting more general pedagogical\\nrules from the detailed rl-induced pedagogical rules? in order to investigate this question, we will build dts using the\\nrules in a rl-induced policy as training examples and empirically evaluate the effectiveness of the extracted set of dt\\nrules by comparing it to the full set of rl-induced rules in a\\nclassroom study. the state features in the rl-induced policies are the input features for the dt and the pedagogical\\nactions are the output labels. in our empirical evaluation,\\nwe separate the pedagogical decisions from the instructional\\ncontent, strictly controlling the content so that it is equivalent for all participants by 1) using an its which provides\\nequal support for all learners; and 2) focusing on tutorial\\ndecisions that cover the same domain content, in this case\\nwe versus ps.\\n\\n2. background\\n2.1 applying rl to itss\\nbeck et al. applied rl to induce pedagogical policies that\\nwould minimize the time students take to complete problems on animalwatch, an its for grade school arithmetic\\n[2]. they trained the model with simulated students. the\\nlow cost of generated data allowed them to apply a modelfree rl method, temporal difference learning. during the\\ntest phase, the induced policies were added to animalwatch\\nand the new system was empirically compared with the original system. their results showed that the policy group\\nspent significantly less time per problem than their no-policy\\npeers. note that their primary goal was to reduce the amount\\nof time per problem, however faster problem-solving does\\nnot always result in better learning performance. nonetheless, their results showed that rl can be successfully applied\\nto induce pedagogical policies for itss.\\niglesias et al., on the other hand, focused on applying rl to\\nimprove the effectiveness of an intelligent educational system that teaches students database design [8, 9]. they\\napplied another model-free rl algorithm, q-learning to induce policies that provide students with direct navigation\\nsupport through the system’s content. they used simulated\\nstudents to induce the policy and empirically evaluated its\\neffectiveness on real students. their results showed that\\nwhile the policy led to more effective system usage behaviors from students, the policy students did not outperform\\nthe no-policy peers in terms of learning outcomes.\\nshen investigated the impact of both immediate and delayed reward functions on rl-induced policies and empirically evaluated the effectiveness of the induced policies within\\n\\n\\n\\n113\\n\\n\\x0can intelligent tutoring system called deep thought [15].\\nthe induced pedagogical policies are used to decide whether\\nthe next task should be we or ps. they found that some\\nlearners benefited significantly more from effective pedagogical policies than others.\\nfinally, chi et al. applied model-based rl to induce pedagogical policies to improve the effectiveness of an intelligent\\nnatural language tutoring system for college-level physics\\ncalled cordillera [4]. the authors collected an exploratory\\ncorpus by training human students on an its that makes\\nrandom decisions and then applied rl to induce pedagogical policies from the corpus. they showed that the induced\\npolicies were significantly more effective than the prior ones.\\nin short, prior studies have shown that rl-induced pedagogical policies can improve students’ learning or reduce\\ntraining time. however, all of these studies focused on the\\neffectiveness of the rl-induced policies. none of them considered extracting more general rules from the induced policies.\\n\\n2.2\\n\\nextracting general rules\\n\\nin addition to the work of davidson et al. [6] and reinchard\\net al. [13], dts have been used for other tasks. vayssiers\\net al., for example, applied classification and regression\\ntrees to predict the presence of 3 species of oak in california [18]. their training examples were vegetation type map\\nrecords for 2085 unique locations. each record consisted of\\n25 climatic and geographic features as well as 3 labels showing the presence of the species (quercus agrifolia, quercus\\ndouglasii and quercus lobata). one dt was induced for\\neach type. the dts were tested on another dataset which\\ncontains the same type of records for 2016 locations. for\\nquercus agrifolia, the induced tree had 10 leaf nodes and\\n94.9% of its predictions are correct for the locations that\\nhave the presence of this oak (sensitivity) while 86.7% of\\nits predictions are correct for cases without the oak (specificity). for quercus douglasii, the induced tree had 22 leaf\\nnodes and a sensitivity and specificity of 87% and 79.9%\\nrespectively. for quercus lobata, the tree had 6 leaves but\\nreached a sensitivity of 77% and a specificity of 73.3%.\\nthus, prior studies have shown that dt can effectively extract a small set of general decision-making rules from a\\nlarge set of specific examples. however, all the examples\\nused by these studies were observations of existing phenomena. so far as we know, this work is the only relevant research on the application of dt to extract a compact set\\nof decision-making rules directly from full rl-induced rules\\nand empirically evaluated the two sets of the rules.\\n\\n2.3\\n\\napplying dt to rl\\n\\nprior research on incorporating dt with rl has largely\\nfocused on seeking a better representation of state space\\nor policy for rl. boutilier et al [3]. proposed representational and computational techniques for markov decision\\nprocesses (mdps) to reduce the size of the state space.\\nthey used dynamic bayesian networks and dts to represent stochastic actions as well as dts to represent rewards.\\nbased upon this representation, they then developed algorithms to find conditional optimal policies. their method\\nwas empirically evaluated on several planning problems and\\n\\nthey showed significant savings in both time and space for\\nsome types of problems. gupta et al. proposed the policy\\ntree algorithm for rl. this algorithm is designed to directly\\ninduce a functional representation of the conditional optimal\\npolicies as a dt. they evaluated it on a variety of domains\\nand showed that it was able to make splits properly [7].\\nin short, prior researchers have shown that properly combining dt with rl can result in a large amount of savings\\nin time and space for finding good policies. however, none\\nof these studies directly applied dt on rl-induced policies.\\n\\n3.\\n\\ninduce full set of rl-policy\\n\\npreviously, researchers have typically used the markov decision process (mdp) [16] framework to model user-system\\ninteractions. the central idea behind this approach is to\\ntransform the problem of inducing effective pedagogical policies on what action the agent should take to the problem of\\ncomputing an optimal policy for an mdp.\\n\\n3.1 markov decision process\\nan mdp is a mathematical framework for representing an\\nrl task. it is defined by: a tuple hs , a, t , ri. where s =\\n{s1 , s2 , ..., sn } denotes the state space; a = {a1 , a2 , ..., am }\\nrepresents a set of agent’s possible actions; and t : s × a ×\\ns → [0, 1] is a transition probability table, where each element is tsai sj = p(sj |si , a). this in turn indicates the\\nprobability of transiting from state si to state sj by taking an action a while r : s × a × s → r assigns rewards\\nto state transitions given actions. the policy is defined as\\nπ : s → a, mapping state s into action a with the goal of\\nmaximizing the expected reward.\\nafter defining an mdp, we can transfer the student-system\\ninteraction dialog into the trajectory which can then be represented as follows:\\na ,r\\n\\na ,r\\n\\na ,r\\n\\n1\\n2\\n3\\ns1 −−1−−→\\ns2 −−2−−→\\ns3 −−3−−→\\n... → sn\\n\\na ,r\\n\\ni\\nwhere si −−i−−→\\nsi+1 means that the tutor executed action\\nai and received reward ri in state si , and then transferred\\nto the next state si+1 . in general, the reward can be divided\\ninto two categories, immediate and delayed, where immediate rewards are received during the state transition, and\\ndelayed are available after reaching to goal state.\\n\\n3.2 training datasets\\nour training dataset was collected from three exploratory\\nstudies in which students were trained on an its which made\\nrandom yet reasonable pedagogical decisions. the studies\\nwere given as homework assignments during csc226: discrete mathematics, a core cs course offered at ncsu during the fall 2014, spring 2015 and fall 2015 semesters. the\\ndataset contains a total of 149 students’ interaction logs.\\nall students used the same its, followed the same general\\nprocedure, studied the same training materials, and worked\\nthrough the same training problems. in order to model the\\nstudents’ learning process, we extracted a total of 142 state\\nfeature variables, which can be grouped into five categories:\\n1. autonomy (am): the amount of work done by the student: such as the number of problems solved so far pscount\\nor the number of hints requested hintcount.\\n\\n\\n\\n114\\n\\n\\x0c2. temporal situation (ts): the time related information about the work process: such as the average time taken\\nper problem avgtime, or the total time spent solving a problem totalpstime.\\n3. problem solving (ps): information about the current\\nproblem solving context, such as the difficulty of the current\\nproblem probdiff, or whether the student changes the difficulty level newlevel.\\n4. performance (pm): information about the student’s\\nperformance during problem solving: such as the number of\\nright application of rules rightapp.\\n5. student action (sa): the statistical measurement of\\nstudent’s behavior: such as the number of non-empty-click\\nactions that students take actioncount, or the number of\\nclicks for derivation appcount.\\n\\nbased methods and an ensemble method and capped the\\nmaximum number of state feature size to be eight. more\\ndetails of our feature selection methods are described in [14].\\nthe final resulting rl policy involves seven state features\\nand 3706 rules.\\n\\n3.3\\n\\n4.1 unweighted vs. weighted tree\\n\\ninducing rl policies\\n\\nin order to apply rl to induce pedagogical policies, we\\nfirst defined the pedagogical decision-making problem as an\\nmdp. the state representation includes all of the relevant\\nfeatures available at the beginning of each step. the actions are we and ps at the step level. the transition tables were calculated on our training dataset, and our reward\\nfunction includes two types of reward: delayed and immediate. our most important reward is based on normalized\\n), which measures the\\nlearning gain (nlg) ( posttest−pretest\\n1−pretest\\nstudents’ learning gains irrespective of their incoming competence. this reward was given as a delayed reward as nlg\\nscores can only be calculated after students finish the entire\\ntraining process. however, shen et al. [15] showed that giving immediate rewards can lead to the production of more\\neffective policies when compared to delayed rewards. this\\nis known as the credit-assignment problem. the more that\\nwe delay success measures from a series of sequential decisions, the more difficult it becomes to identify which of the\\ndecision(s) in the sequence are responsible for our final success or failure. therefore, for the purposes of this study we\\nalso assigned immediate rewards based upon the students’\\nperformance during training on the system.\\nthe value iteration algorithm was applied to find the optimal\\npolicy. this algorithm operates by finding the optimal value\\nfor each state v ∗ (s). the optimal value for a given state is\\nthe expected discounted reward that the agent will gain if\\nit starts in s and follows the optimal policy to the goal.\\ngenerally speaking, v ∗ (s) can be obtained by the optimal\\nvalue function for each state-action pair q∗ (s, a) which is\\ndefined as the expected discounted reward the agent will\\ngain if it takes an action a in a state s and follows the optimal\\npolicy to the end. the optimal state value v ∗ (s) and value\\nfunction q∗ (s, a) can be obtained by iteratively updating\\nv (s) and q(s, a) via equations 1 and 2 until they converge:\\nx\\nq(s, a) := r(s, a) + γ\\np(sj |si , a)v (s0 )\\n(1)\\nv (s)\\n\\n:=\\n\\ns0 ∈s\\n\\nmax q(s, a)\\na\\n\\n(2)\\n\\nhere, p(sj |si , a) is the estimated transition model t , r(s, a)\\nis the estimated reward model and 0 ≤ γ ≤ 1 is a discount\\nfactor.\\nto induce effective pedagogical policies, we combined rl\\nwith various feature selections including 10 types of correlation-\\n\\n4.\\n\\nextracting compact dt-rl sets\\n\\nin order to extract a more compact set of decision-making\\nrules from the full set of rl-induced rules, we implemented\\nthe id3 algorithm to build dts [12]. each rule in the final\\nrl-induced policy was used as a training example. two\\ntypes of decision trees were built: unweighted and weighted,\\nas well as two types of pruning strategies were implemented:\\npre- and post-pruning. next, we will discuss each of them\\nin turn.\\n\\nthe decision to give a we vs. ps may impact students’\\nlearning differently in different situations. we therefore built\\ntwo types of decision trees: unweighted and weighted. unweighted trees treated each decision equally while weighted\\ntrees take account of the relative importance of each pedagogical rule. when applying the value iteration algorithm\\nto induce the optimal policy, we generate the optimal value\\nfunction q∗ (s, a), which gives the expected discounted reward each agent will gain if it takes an action a in a state s\\nand follows the optimal policy to the end. for a given state\\ns, a large difference between the values of q(s, “p s”) and\\nq(s, “w e”) indicates that it is more important for the its\\nto follow the optimal decision in the state s. we therefore\\nused the absolute difference between the q values for each\\nstate s to weight each rl pedagogical rule.\\nthe id3 algorithm builds a tree recursively from root to\\nleaves. on each iteration of the construction process the\\nalgorithm will check the state of the dataset for the current\\nbranch. it will then select a test feature for the current\\nnode based upon the weighted information gain. the current\\nnode will then be expanded by adding branches to it, each\\nof which represents a possible value for the selected feature.\\nthe data will be partitioned over the branches according to\\nthe value of the test feature. the selected feature cannot\\nbe used again by its children. weighted information gain is\\ndefined by the difference between the weighted entropy of the\\nexamples before it is selected and after they are separated\\nby feature value. the weighted entropy of a node can be\\ncalculated by equation 3\\nh(g) = −\\n\\nj\\nx\\n\\np(i|g)log2 p(i|g)\\n\\n(3)\\n\\ni=1\\n\\nj is the total number of output label classes. in our case,\\nit is the number of pedagogical actions (we or ps) which\\nis 2 . p(i|g) is the\\nweighted frequency defined by the equap\\np\\nw\\ntion: p(i|g) = p x∈i wxy .\\nx∈i wx is the total weight of the\\ny∈g\\nexamples\\nwhich\\nare\\nin\\nnode\\ng and which belong to class i.\\np\\nand y∈g wy is the total weights of examples in node g.\\nthe information gain of spliting the current set of training\\nexamples using feature f can be calculated by equation 4:\\nig(f, g) = h(g) −\\n\\n\\n\\nk\\nx\\nj=1\\n\\np(tj |g)h(tj )\\n\\n(4)\\n\\n115\\n\\n\\x0cp(tj |g) is the\\nweighted frequency of the examples in node g:\\np\\np\\nxf =t,x∈g wx\\np\\np(tj |g) =\\n.\\nxf =t,x∈g wx is the total weights\\ny∈g wy\\nof\\nexamples\\nin\\nnodes\\ng\\nwhose\\nvalue of feature f is j and\\np\\ny∈g wy is the total weight of examples in nodes g.\\n\\n4.2\\n\\npre-pruning and post-pruning\\n\\nto control the size of rules induced by dt, we examined\\ntwo types of pruning strategy: pre- and post-pruning. the\\npre-pruning is conducted during the process of building the\\ntree and it used the information gain to determine whether\\nto expand or to terminate. only nodes with an information\\ngain greater than a threshold times its depth: ig(f, g) ≥\\nθ × dg will be expanded and others will be made as a leaf.\\nθ is a fixed threshold and dg is the depth of node g.\\npost-pruning is conducted after the whole decision tree is\\nbuilt and it used the error rate as the pruning measure. the\\nerror\\nrate before a node is expanded is defined as: eg =\\np\\ni∈i wi\\n. i is the set of the decisions incorrectly classified\\n|g|\\nby node g and |g| is the total number of examples in the\\nnode g. the\\np error\\np rate after a node is expanded is defined\\nwi\\nas: ec = c∈c |g|j∈ic . c is the set of children nodes\\nof g after it is expanded and ic is the set of the decisions\\nincorrectly classified by the node c. in post-pruning, if the\\ndifference of a node’s error rate from before to after split is\\nless than a threshold, the node will be pruned by removing\\nall of its branches to make it a leaf node.\\n\\n4.3\\n\\nthe compact set of dt-rl rules\\n\\nin order to induce a compact set of dt-rl rules, we applied the dts to the full set of 3706 rl-induced rules. the\\ninduced unweighted and weighted dts without pruning has\\n2527 and 2456 rules (leaf nodes) respectively. thus, without pruning, dts are already able to extract a smaller set\\nof rules: it reduced the total number of rules by over 1000.\\nfigure 1 shows the relationship between the number of leaf\\nnodes (x-axis) and the inverted weighted accuracy (y-axis).\\nweighted accuracy(w a) is the weighted percentage of decisions correctlypmade, which can be calculated by the equation: w a =\\n\\ndi ∈t\\n\\np\\n\\ndi\\n\\nwi\\n\\nwi\\n\\n. t is the set of correct predictions\\n\\nmade by a dt and wi is the weight of decision i. the inverted weighted accuracy (iw a) is iw a = w a−10 , the\\nlower the better. since our goal is to find a good balance\\npoint between the iwa and the number of leaf nodes, we\\napplied a widely used strategy called the elbow method,\\nto select the best tree. as we can see in the figure, the\\nelbows for the two unweighted tree approaches are around\\n800 and 1700 rules (x-axis) for the pre and post pruning\\nrespectively while the elbows for the two weighted tree approaches are around 250 and 500 for the pre and post pruning respectively. so it seems that weighted tree can extract\\nmore compact set of rules than the unweighted trees. while\\nthe weighted pre-pruning approach has around 250 rules,\\nits iwa is much higher than the weighted post-pruning approach. therefore, we chose the weighted tree with postpruning strategy which has the an elbow at about 500 leaf\\nnodes and reasonable iwa.\\nto further justify our dt choice, table 1 shows the relationship between the pruning thresholds, w a and the number\\n\\nfigure 1: leaf nodes - accuracy\\nof leaf nodes for the weighted tree with post-pruning. table 1 shows that the tree with the closest number of leaves\\nto 500 is the 529 one. it can be obtained by apply a pruning\\nthreshold of 0.8 and the result tree has a weighted accuracy\\nof 0.76. the rules in the resulted tree will be the rules used\\nin the dt-rl condition.\\nin short, we applied dt on rl-induced pedagogical policies\\nto extract a more compact set of decision-making rules. the\\neffectiveness of the original full set and the compact set of\\npolicies were empirically compared against a baseline policy\\nwhich makes random yet reasonable decisions: ps vs. we.\\nthus, we have three conditions:\\n1. full-rl: the full set of 3706 rl-induced rules.\\n2. dt-rl: the compact set of 529 dt-induced rl rules.\\n3. random: the random yet reasonable policy.\\n\\n5.\\n\\nempirical experiment\\n\\nparticipants: this study was conducted in the undergraduate discrete mathematics course at the department\\nof computer science at nc state university in the fall of\\n2016. 153 students participated in this study, which was\\ngiven as their final homework assignment.\\nconditions: students in the study were assigned to three\\nconditions via balanced random assignment based upon their\\ncourse section and performance on the class mid-term exam.\\nsince the primary goal of this work is to examine the effectiveness of the two rl based policies, we assigned more\\nstudents to the full-rl and dt-rl conditions than in the\\nrandom condition. the final group sizes were: n = 61 (fullrl), n = 51 (dt-rl), and n = 41 (random).\\ndue to preparations for exams and length of the experiment,\\n126 students completed the experiment. 5 students were\\nexcluded from the subsequent analysis due to perfect pretest\\nscores, working in group or gaming the system during the\\ntraining. the remaining 121 students were distributed as\\nfollows: n = 45 for full-rl; n = 41 for rl-dt; n = 35\\nfor random. we performed a χ2 test of the relationship\\nbetween students’ condition and their rate of completion\\nand found no significant difference among the conditions:\\nχ2 (2) = 0.955, p = 0.620.\\nprobability tutor: pyrenees is a web-based its for probability. it covers 10 major principles of probability, such\\nas the complement theorem and bayes’ rule. pyrenees\\n\\n\\n\\n116\\n\\n\\x0cthreshold\\nwa\\nleaves\\n\\ntable 1: weighted dt with post-pruning\\n0\\n0.1\\n0.2\\n0.3\\n0.4\\n0.5\\n0.6\\n0.7\\n1.00 0.99 0.98 0.96 0.93 0.89 0.85 0.79\\n2456 2217 2029 1809 1608 1383 1043 758\\n\\nprovides step-by-step instruction and immediate feedback.\\npyrenees can also provide on-demand hints prompting the\\nstudent with what they should do next. as with other systems, help in pyrenees is provided via a sequence of increasingly specific hints. the last hint in the sequence, the\\nbottom-out hint, tells the student exactly what to do. for\\nthe purposes of this study we incorporated three distinct\\npedagogical decision modes into pyrenees to match the three\\nconditions.\\nprocedure: in this experiment, students were required to\\ncomplete 4 phases: 1) pre-training, 2) pre-test, 3) training on\\npyrenees, and 4) post-test. during the pre-training phase,\\nall students studied the domain principles through a probability textbook, reviewed some examples, and solved certain\\ntraining problems. the students then took a pre-test which\\ncontained 14 problems. the textbook was not available at\\nthis phase and students were not given feedback on their answers, nor were they allowed to go back to earlier questions.\\nthis was also true of the post-test.\\nduring phase 3, students in all three conditions received\\nthe same 12 rather complicated problems in the same order\\non pyrenees. each main domain principle was applied at\\nleast twice. the minimal number of steps needed to solve\\neach training problem ranged from 20 to 50. these steps\\nincluded defining variables, applying principles, and solving equations. the number of domain principles required to\\nsolve each problem ranged from 3 to 11. all of the students\\ncould access the corresponding pre-training textbook during this phase. each step in the problems could have been\\nprovided as either a we or ps based upon the condition\\npolicy. finally, all of the students completed a post-test\\nwith 20 problems. 14 of the problems were isomorphic to\\nthe pre-test given in phase 2. the remaining six were nonisomorphic complicated problems.\\ngrading criteria: the test problems required students to\\nderive an answer by writing and solving one or more equations. we used three scoring rubrics: binary, partial credit,\\nand one-point-per-principle. under the binary rubric, a solution was worth 1 point if it was completely correct or 0\\nif not. under the partial credit rubric, each problem score\\nwas defined by the proportion of correct principle applications evident in the solution. a student who correctly applied 4 of 5 possible principles would get a score of 0.8. the\\none-point-per-principle rubric in turn gave a point for each\\ncorrect principle application. all of the tests were graded in\\na double-blind manner by a single experienced grader. the\\nresults presented below are based upon the partial-credit\\nrubric but the same results hold for the other two. for\\ncomparison purposes, all test scores were normalized to the\\nrange of [0,1].\\n\\n6.\\n\\n0.8\\n0.76\\n529\\n\\n0.9\\n0.68\\n231\\n\\nempirical results\\n\\nsince both the full-rl and dt-rl policies are based on an\\nrl-induced policy, we combined the two conditions together\\nas the induced group to evaluate the effectiveness the rlinduced policy. the evaluation was conducted by comparing\\nthe induced group with the baseline random condition on\\nlearning performance and training time. moreover, in order to further discover to what extent the compact policy\\nretained the power of the full policy, we compared the fullrl and dt-rl conditions on the same measures. next, we\\nwill discuss each of the comparisons in turn.\\n\\n6.1 induced vs. random\\nwe measured students’ incoming competence via the pretest scores collected before training took place. table 2\\nshows a comparison between the induced group and the\\nrandom group in terms of learning performance. the parenthesized values following the group names in row 1 denote\\nthe number of students in each group. the second row in this\\ntable shows the pre-test scores. the last column shows the\\npairwise t-test results. pairwise t-tests on students’ pre-test\\nscores show that there is no significant difference between\\nthe two groups: t(119) = −0.346, p = 0.730, d = 0.069.\\nthus, despite attrition, the two groups remained balanced\\nin terms of incoming competence. next, we will compare the\\ntwo groups in terms of learning performance in the post-test\\nand training time.\\nrows 2 - 4 in table 2 show a comparison of the pre-test, isomorphic post-test (14 isomorphic questions), and adjusted\\npost-test scores between the two groups along with the mean\\nand sd for each. in order to examine the students’ improvement through training on pyrenees, we compared their\\nscores on the pre-test and isomorphic post-test questions.\\na repeated measures analysis using test type (pre-test and\\nisomorphic post-test) as factors and test score as the dependent measure showed a main effect for test type: f (1, 119) =\\n98.75, p < 0.0001. further comparisons on group by group\\nbasis showed that on the isomorphic questions, both groups\\nscored significantly higher in the post-test than in the pretest: f (1, 85) = 81.30, p < 0.0001 for induced and f (1, 34) =\\n18.30, p = 0.0001 for random respectively. this suggests\\nthat the basic practice and problems, domain exposure, and\\ninteractivity of our its might help students to learn even\\nwhen pedagogical decisions are made randomly.\\nin order to investigate the effectiveness of the induced policies, we compared students’ overall learning performance,\\nwhich was evaluated by their adjusted post-test scores, between the two groups. a one-way ancova analysis was\\nconducted on their overall post-test scores (20 questions),\\nusing the pretest scores as a covariate to factor out the influence of their incoming competence. the result shows a\\nsignificant main effect: f (1, 118) = 4.628, p = 0.033. that\\nis, the induced group significantly outperformed the random group on adjusted post-test scores, which is shown in\\n\\n\\n\\n117\\n\\n\\x0ccond\\npre\\niso post\\nadjusted post\\ntime\\nwe steps\\nps steps\\nwe pct(%)\\n\\ntable 2: induced vs. random\\ninduced(86)\\nrandom(35)\\nt-test result\\n.686(.194)\\n.699(.171)\\nt(119) = −0.346, p = 0.730, d = 0.069\\n.851(.155)\\n.812(.195)\\nt(119) = 1.141, p = 0.256, d = 0.229\\n.751(.144)\\n.689(.138)\\nt(119) = 2.162, p = 0.033, d = 0.433\\n105.87(34.30) 111.18(27.33) t(119) = −0.815, p = 0.417, d = 0.163\\n205.74(62.73) 189.46(11.39)\\nt(119) = 1.522, p = 0.131, d = 0.305\\n173.69(61.14) 190.26(10.28) t(119) = −1.591, p = 0.114, d = 0.319\\n54.16(16.35)\\n49.89(2.78)\\nt(119) = 1.532, p = 0.128, d = 0.307\\n\\nthe fourth row of table 2. therefore, the results showed that\\nthe induced policies are significantly more effective than the\\nrandom policy.\\nthe fifth row in table 2 shows the average amount of total\\ntraining time (in minutes) students spent on our its for each\\ngroup. pairwise t-test showed no significant difference in\\ntraining time between the two groups: t(119) = −0.815, p =\\n0.417, d = 0.163. the results suggest that when compared\\nto the random policy, the induced policies generally do not\\nhave a significant different impact on students’ training time.\\nthe last three rows in table 2 show the number of we\\nand ps steps given as well as the percentage of we steps\\nreceived by the induced and the random group. pairwise\\nt-tests showed that there is no significant difference between\\nthe two groups on these three measures.\\n\\n6.2\\n\\nfull-rl vs. dt-rl\\n\\nwe then performed the same comparison between the fullrl and dt-rl conditions in order to examine the effectiveness of the dt-extracted compact policy. the second row\\nin table 3 shows the pre-test scores for each condition. a\\npairwise t-test on the scores shows no significant difference\\nbetween the two conditions: t(84) = −0.168, p = 0.867,\\nd = 0.036. thus the two conditions were balanced in terms\\nof incoming competence.\\nthe pre-test, isomorphic post-test and adjusted post-test\\nscores are shown in rows 2 - 4 of table 3. a repeated measures analysis using test type (pre-test and isomorphic posttest) as factors and test score as dependent measure showed\\na main effect for test type: f (1, 85) = 81.30, p < 0.0001.\\nfurther comparisons on group by group basis showed that\\nboth conditions scored significantly higher in isomorphic\\npost-test than in pre-test: f (1, 44) = 42.16, p < 0.0001\\nfor full-rl and f (1, 40) = 39.16, p < 0.0001 for dt-rl.\\nthese results suggest that the students can effectively learn\\nfrom pyrenees with the full and compact policies.\\nin order to discover to what degree the compact policy retained the effectiveness of the full policy, we compared the\\npost-test scores between the two conditions. the results\\nof a pairwise t-test showed no significant different between\\nthem on isomorphic post-test: t(84) = 0.505, p = 0.615,\\nd = 0.109. we also conducted an ancova analysis on the\\noverall post-test scores using the pretest scores as a covariate and still found no significant different between the two\\nconditions: f (1, 83) = 0.348, p = 0.557. in short, while on\\npost-test scores, the dt-rl condition scored slightly lower\\nthan the full-rl condition, the difference is not significant.\\n\\nthe fifth row of table 3 shows the average amount of time\\nstudents spent on training. as the row shows, the fullrl condition spent significantly more time than the dt-rl\\ncondition: t(84) = 3.829, p = 0.0002, d = 0.827. thus\\nthe full-rl and dt-rl policies have significant different\\nimpact upon the students’ training time.\\nthe last three rows of table 3 show the number of we\\nand ps steps given and the percentage of we steps received by the full-rl and the dt-rl condition. pairwise t-tests showed that comparing to the dt-rl condition, the full-rl condition received significantly fewer we\\nsteps: t(84) = −4.952, p < 0.0001, d = 1.069; received a\\nlower percentage of we steps: t(84) = −4.955, p < 0.0001,\\nd = 1.070; and completed more ps steps: t(84) = 4.999,\\np < 0.0001, d = 1.079. these results suggest that the pedagogical decisions made by the compact and full policies are\\nsubstantively different.\\n\\n7.\\n\\ndiscussion\\n\\nin this study, we applied dt to extract a compact set of\\npedagogical rules from the full set of rl-induced rules and\\nempirically evaluated the effectiveness of two sets of rules in\\na classroom study. our goal was to shed some light on the\\nrl-induced policies and we think this is only the first step\\ntowards narrowing the gap and building a bridge between\\nmachine-induced pedagogical policies and learning theories.\\nin order to find the best dt, we explored two types of tree:\\nunweighted and weighted; and for each of them, we conducted two types of pruning strategy: pre- and post-pruning.\\nafter comparing the performance among them, we selected\\nthe weighted tree with the post-pruning strategy to perform\\nthe extraction of general decision-making rules. the rlinduced policy contains 3706 specific rules, and the compact\\ndt-rl consisted of 529 rules with a weighted decision accuracy of 76%.\\nin our empirical experiment, we were able to strictly control\\nthe domain content and thus to isolate the impact of pedagogy from content. based on this isolation, we compared\\nstudents’ performance with the full-rl policy, the dt-rl\\npolicy and the baseline random policy. our results showed\\nthat students in all three conditions learned significantly after training on pyrenees, this suggests that the basic training\\nof the its is effective, even when the pedagogical decisions\\nare made randomly. to evaluate the effectiveness of the two\\nmachine induced policies (full-rl policy and dt-rl policy), we combined the full-rl and dt-rl condition as the\\ninduced group and compared its learning performance with\\nthe random group. our results showed that the induced\\n\\n\\n\\n118\\n\\n\\x0ccond\\npre\\niso post\\nadjusted post\\ntime\\nwe steps\\nps steps\\nwe pct(%)\\n\\ntable 3: full-rl vs. dt-rl\\nfull-rl(45)\\ndt-rl (41)\\nt-test result\\n.683(.205)\\n.690(.184)\\nt(84) = −0.168, p = 0.867, d = 0.036\\n.859(.145)\\n.842(.168)\\nt(84) = 0.505, p = 0.615, d = 0.109\\n.757(.144)\\n.739(.145)\\nt(84) = 0.594, p = 0.554, d = 0.128\\n118.42(35.000) 92.10(27.95)\\nt(84) = 3.829, p = 0.0002, d = 0.827\\n177.44(48.86) 236.80(62.03) t(84) = −4.952, p < 0.0001, d = 1.069\\n201.47(47.22) 143.20(60.57)\\nt(84) = 4.999, p < 0.0001, d = 1.079\\n46.77(12.78)\\n62.26(16.13) t(84) = −4.955, p < 0.0001, d = 1.070\\n\\ngroup significantly outperform the random group. these\\nresults suggest that the machine induced policies are indeed\\nmore effective than the random policy.\\nfinally, in order to examine to what extent the compact dtrl policy retained the power of the full rl-induced policy,\\nwe compared the learning performance of the full-rl and\\nthe dt-rl conditions. our results suggest that while some\\nof the power was lost in the general rules extraction, the relative performance difference between the full-rl and the\\ndt-rl condition is not significant. in addition, our results\\non the pedagogical decisions made in training revealed that\\nthe compact dt-rl policy selected significant more we\\nthan the full-rl policy. this suggests that the two sets\\nof policies indeed made materially different decisions. however, since the weighted dt took account of the importance\\nof each rule, the dt-rl policy aims to retain maximal decision effectiveness from the full-rl policy while the size of\\nthe former is less than 15% of the size of the full-rl rules.\\nin the future, we will apply existing learning theories to the\\ndecision-making process generated by decision tree to find\\na theoretical basis for the dt-induced general pedagogical\\ndecision-making rules.\\n\\n8.\\n\\nacknowledgements\\n\\nthis research was supported by the nsf grant #1432156:\\n“educational data mining for individualized instruction in\\nstem learning environments” and #1651909: “improving\\nadaptive decision making in interactive learning environments”.\\n\\n9.\\n\\nreferences\\n\\n[1] j. r. anderson, a. t. corbett, k. r. koedinger, and\\nr. pelletier. cognitive tutors: lessons learned. the\\njournal of the learning sciences, 4(2):167–207, 1995.\\n[2] j. beck, b. p. woolf, and c. r. beal. advisor: a\\nmachine learning architecture for intelligent tutor\\nconstruction. aaai/iaai, 2000:552–557, 2000.\\n[3] c. boutilier, r. dearden, and m. goldszmidt.\\nstochastic dynamic programming with factored\\nrepresentations. artificial intelligence, 121(1):49–107,\\n2000.\\n[4] m. chi, k. vanlehn, d. litman, and p. jordan.\\nempirically evaluating the application of\\nreinforcement learning to the induction of effective\\nand adaptive pedagogical strategies. user modeling\\nand user-adapted interaction, 21(1-2):137–180, 2011.\\n[5] l. j. cronbach and r. e. snow. aptitudes and\\ninstructional methods: a handbook for research on\\ninteractions. irvington, 1977.\\n\\n[6] a. d. davidson and et al. multiple ecological pathways\\nto extinction in mammals. proceedings of the national\\nacademy of sciences, 106(26):10702–10705, 2009.\\n[7] u. d. gupta, e. talvitie, and m. bowling. policy tree:\\nadaptive representation for policy gradient. in aaai,\\npages 2547–2553, 2015.\\n[8] a. iglesias, p. martı́nez, r. aler, and f. fernández.\\nlearning teaching strategies in an adaptive and\\nintelligent educational system through reinforcement\\nlearning. applied intelligence, 31(1):89–106, 2009.\\n[9] a. iglesias, p. martı́nez, r. aler, and f. fernández.\\nreinforcement learning of pedagogical policies in\\nadaptive and intelligent educational systems.\\nknowledge-based systems, 22(4):266–270, 2009.\\n[10] k. r. koedinger and et al. intelligent tutoring goes to\\nschool in the big city. ijaied, 8(1):30–43, 1997.\\n[11] p. phobun and j. vicheanpanya. adaptive intelligent\\ntutoring systems for e-learning systems.\\nprocedia-social and behavioral sciences,\\n2(2):4064–4069, 2010.\\n[12] j. r. quinlan. induction of decision trees. machine\\nlearning, 1(1):81–106, 1986.\\n[13] s. h. reichard and c. w. hamilton. predicting\\ninvasions of woody plants introduced into north\\namerica. conservation biology, 11(1):193–203, 1997.\\n[14] s. shen and m. chi. aim low: correlation-based\\nfeature selection for model-based reinforcement\\nlearning. edm, 2016.\\n[15] s. shen and m. chi. reinforcement learning: the\\nsooner the better, or the later the better? in umap,\\npages 37–44. acm, 2016.\\n[16] r. s. sutton and a. g. barto. reinforcement learning:\\nan ']\n",
      "['\\nwe present results of a randomized controlled study that\\ncompared different types of affective messages delivered by\\npedagogical agents. we used animated characters that were\\nempathic and emphasized the malleability of intelligence and\\nthe importance of effort. results showed significant correlations between students who received more empathic messages and those who were more confident, more patient, exhibited higher levels of interest, and valued math knowledge\\nmore. students who received more growth mindset messages, tended to get more problems correct on their first\\nattempt but valued math knowledge less and had lower\\nposttest scores. students who received more success/failure\\nmessages tended to make more mistakes, to be less learningoriented, and stated that they were more confused. we conclude that these affective messages are powerful media to\\ninfluence students’ perceptions of themselves as learners, as\\nwell as their perceptions of the domain being taught. we\\nhave reported significant results that support the use of empathy to improve student affect and attitudes in a math\\ntutor.\\n\\nkeywords\\nstudent affect, empathy messages, growth mindset, pedagogical agents, intelligent tutor, confidence\\n\\n1. ']\n",
      "['\\nexpertise in a domain of knowledge is characterized by a greater\\nfluency for solving problems within that domain and a greater\\nfacility for transferring the structure of that knowledge to other\\ndomains. deliberate practice and the feedback that takes place\\nduring practice activities serve as gateways for developing domain\\nexpertise. however, there is a difficulty in consistently aligning\\nfeedback about a learner’s practice performance with the intended\\nlearning outcomes of those activities – especially in situations\\nwhere the person providing feedback is unfamiliar with the\\nintention of those activities. to address this problem, we propose\\nan intelligent model to automatically label opportunities for\\npractice (assessment questions) according to the learning outcomes\\nintended by the course designers. as a proof of concept, we used a\\nreduced version of bloom’s taxonomy to define the intended\\nlearning outcomes. using a factorial design, we employed term\\nfrequency-inverse document frequency (tf-idf) and latent\\ndirichlet allocation (lda) to transform questions from text to word\\nweightages with support vector machine (svm) and extreme\\nlearning machine (elm) to train and automatically label the\\nquestions. we trained our models with 120 questions labeled by the\\nsubject matter expert of an undergraduate engineering course.\\ncompared to existing works which create models based on a selfgenerated dataset, our proposed approach uses 30 untrained\\nquestions from online/textbook sources to validate the performance\\nof our models. exhaustive comparison analysis of the testing set\\nshowed that tf-idf with elm outperformed the other\\ncombinations by yielding 0.86 reliability (f1 measure) with the\\nsubject matter expert.\\n\\nkeywords\\nlearning outcomes, term frequency-inverse document frequency,\\nlatent dirichlet allocation, extreme learning machine, support\\nvector machine\\n\\n1. ']\n",
      "['\\nwe propose a new model for learning that relates videowatching behavior and engagement to quiz performance. in\\nour model, a learner’s knowledge gain from watching a lecture\\nvideo is treated as proportional to their latent engagement\\nlevel, and the learner’s engagement is in turn dictated by a set\\nof behavioral features we propose that quantify the learner’s\\ninteraction with the lecture video. a learner’s latent concept\\nknowledge is assumed to dictate their observed performance\\non in-video quiz questions. one of the advantages of our\\nmethod for determining engagement is that it can be done\\nentirely within standard online learning platforms, serving\\nas a more universal and less invasive alternative to existing\\nmeasures of engagement that require the use of external\\ndevices. we evaluate our method on a real-world massive\\nopen online course (mooc) dataset, from which we find that\\nit achieves high quality in terms of predicting unobserved\\nfirst-attempt quiz responses, outperforming two state-of-theart baseline algorithms on all metrics and dataset partitions\\ntested. we also find that our model enables the identification\\nof key behavioral features (e.g., larger numbers of pauses\\nand rewinds, and smaller numbers of fast forwards) that are\\ncorrelated with higher learner engagement.\\n\\nkeywords\\nbehavioral data, engagement, latent variable model, learning\\nanalytics, mooc, performance prediction\\n\\n1.\\n\\n']\n",
      "['\\nwe investigate generalizability of face-based detectors of mind\\nwandering across task contexts. we leveraged data from two lab\\nstudies: one where 152 college students read a scientific text and\\nanother where 109 college students watched a narrative film. we\\nautomatically extracted facial expressions and body motion\\nfeatures, which were used to train supervised machine learning\\nmodels on each dataset, as well as a concatenated dataset. we\\napplied models from each task context (scientific text or narrative\\nfilm) to the alternate context to study generalizability. we found\\nthat models trained on the narrative film dataset generalized to the\\nscientific text dataset with no modifications, but the predicted mind\\nwandering rate needed to be adjusted before models trained on the\\nscientific text dataset would generalize to the narrative film dataset.\\nadditionally, we analyzed generalizability of individual features\\nand found that the lip tightener and jaw drop action units had the\\ngreatest potential to generalize across task contexts. we discuss\\nfindings and applications of our work to attention-aware learning\\ntechnologies.\\n\\nkeywords\\nmind wandering, mental states, attention aware interfaces,\\ncross-corpus training.\\n\\n1. ']\n",
      "['\\nin this paper, we investigate the relationship between students’\\nlearning gains and their compliance with prompts fostering selfregulated learning (srl) during interaction with metatutor, a\\nhypermedia-based intelligent tutoring systems (its). when possible, we evaluate compliance from student explicit answers on\\nwhether they want to follow the prompts, when such answers are\\nnot available, we mine several student behaviors related to prompt\\ncompliance. these behaviors are derived from students’ eyetracking and interaction data (e.g., time spent on a learning page,\\nnumber of gaze fixations on that page). our results reveal that\\ncompliance with some, but not all srl prompts provided by\\nmetatutor do influence learning. these results contribute to gain\\na better understanding of how students benefit from srl prompts,\\nand provides insights on how to further improve their effectiveness. for instance, prompts that do improve learning when followed could be the focus of adaptation designed to foster compliance for those students who would disregard them otherwise.\\nconversely, prompts that do not improve learning when followed\\ncould be improved based on further investigations to understand\\nthe reason for their lack of effectiveness\\n\\nkeywords\\nintelligent tutoring systems; self-regulated learning; scaffolding;\\ncompliance with prompts; learning gains; eye tracking; linear\\nregression; hypermedia\\n\\n1. ']\n",
      "['\\n\\nproblem-solving skills in creative, open-ended domains are both\\nimportant and little understood. these domains are generally illstructured, have extremely large exploration spaces, and require\\nhigh levels of specialized skill in order to produce quality solutions.\\nwe investigate problem-solving behavior in one such domain, the\\nscientific-discovery game foldit. our goal is to discover differentiating patterns and understand what distinguishes high and low levels\\nof problem-solving skill. to address the challenges posed by the\\nscale, complexity, and ill-structuredness of foldit solver behavior\\ndata, we devise an iterative visualization-based methodology and use\\nthis methodology to design a concise, meaning-rich visualization of\\nthe problem-solving process in foldit. we use this visualization to\\nidentify key patterns in problem-solving approaches, and report how\\nthese patterns distinguish high-performing solvers in this domain.\\n\\nkeywords\\n\\nproblem solving; scientific-discovery games; visualization\\n\\n1.\\n\\n']\n",
      "['\\n\\nmassive open online courses (moocs) have demonstrated growing popularity and rapid development in recent years. discussion\\nforums have become crucial components for students and instructors to widely exchange ideas and propagate knowledge. it is important to recommend helpful information from forums to students\\nfor the benefit of the learning process. however, students or instructors update discussion forums very often, and the student preferences over forum contents shift rapidly as a mooc progresses.\\nso, mooc forum recommendations need to be adaptive to these\\nevolving forum contents and drifting student interests. these frequent changes pose a challenge to most standard recommendation\\nmethods as they have difficulty adapting to new and drifting observations. we formalize the discussion forum recommendation\\nproblem as a sequence prediction problem. then we compare different methods, including a new method called context tree (ct),\\nwhich can be effectively applied to online sequential recommendation tasks. the results show that the ct recommender performs\\nbetter than other methods for moocs forum recommendation task.\\nwe analyze the reasons for this and demonstrate that it is because\\nof better adaptation to changes in the domain. this highlights the\\nimportance of considering the adaptation aspect when building recommender system with drifting preferences, as well as using machine learning in general.\\n\\nkeywords\\n\\nmoocs forum recommendation, context tree, model adaptation\\n\\n1. ']\n",
      "['\\nadaptive learning technologies hold great promise for improving the reading skills of adults with low literacy, but\\nadults with low literacy skills typically have low computer\\nliteracy skills. in order to determine whether adults with\\nlow literacy skills would be able to use an intelligent tutoring system for reading comprehension, we adapted a 44 task\\ncomputer literacy assessment and delivered it to 114 adults\\nwith reading skills between 3rd and 8th grade levels. this\\npaper presents four analyses on these data. first, we report\\nthe pass/fail data natively exported by the assessment for\\nparticular computer-based tasks. second, we undertook a\\ngoms analysis of each computer-based task, to predict the\\ntask completion time for a skilled user, and found that it\\nnegatively correlated with proportion correct for each item,\\nr(42) = −.4, p = .01. third, we used the goms task decomposition to develop a q-matrix of component computer\\nskills for each task, and using logistic mixed effects models\\non this matrix identified five component skills highly predictive of the success or failure of an individual on a computer task: function keys, typing, using icons, right clicking,\\nand mouse dragging. and finally, we assessed the predictive\\nvalue of all component skills using logistic lasso.\\n\\nkeywords\\nadult literacy, computer literacy, goms, q-matrix, mixed\\nmodel, lasso\\n\\n1. ']\n",
      "['\\nmind wandering, defined as shifts in attention from task-related\\nprocessing to task-unrelated thoughts, is a ubiquitous\\nphenomenon that has a negative influence on performance and\\nproductivity in many contexts, including learning. we propose\\nthat next-generation learning technologies should have some\\nmechanism to detect and respond to mind wandering in real-time.\\ntowards this end, we developed a technology that automatically\\ndetects mind wandering from eye-gaze during learning from\\ninstructional texts. when mind wandering is detected, the\\ntechnology intervenes by posing just-in-time questions and\\nencouraging re-reading as needed. after multiple rounds of\\niterative refinement, we summatively compared the technology to\\na yoked-control in an experiment with 104 participants. the key\\ndependent variable was performance on a post-reading\\ncomprehension assessment. our results suggest that the\\ntechnology was successful in correcting comprehension deficits\\nattributed to mind wandering (d = .47 sigma) under specific\\nconditions, thereby highlighting the potential to improve learning\\nby “attending to attention.”\\n\\nkeywords\\nmind wandering; gaze tracking; student modeling; attentionaware.\\n\\n1. ']\n",
      "['\\neducational systems typically contain a large pool of items\\n(questions, problems). using data mining techniques we can\\ngroup these items into knowledge components, detect duplicated items and outliers, and identify missing items. to\\nthese ends, it is useful to analyze item similarities, which can\\nbe used as input to clustering or visualization techniques.\\nwe describe and evaluate different measures of item similarity that are based only on learners’ performance data, which\\nmakes them widely applicable. we provide evaluation using\\nboth simulated data and real data from several educational\\nsystems. the results show that pearson correlation is a suitable similarity measure and that response times are useful\\nfor improving stability of similarity measures when the scope\\nof available data is small.\\n\\n1. ']\n",
      "['\\nresearch in educational data mining could benefit from greater\\nefforts to ensure that models yield reliable, valid, and interpretable\\nparameter estimates. these efforts have especially been lacking\\nfor individualized student-parameter models. we collected two\\ndatasets from a sizable student population with excellent “depth”\\n– that is, many observations for each skill for each student. we fit\\ntwo models, the individualized-slope additive factors model\\n(iafm) and individualized bayesian knowledge tracing (ibkt),\\nboth of which individualize for student ability and student\\nlearning rate. estimates of student ability were reliable and valid:\\nthey were consistent across both models and across both datasets,\\nand they significantly predicted out-of-tutor pretest data. in one of\\nthe datasets, estimates of student learning rate were reliable and\\nvalid: consistent across models and significantly predictive of\\npretest-posttest gains. this is the first demonstration that\\nstatistical models of data resulting from students’ use of learning\\ntechnology can produce reliable and valid estimates of individual\\nstudent learning rates. further, we sought to interpret and\\nunderstand what differentiates a student with a high estimated\\nlearning rate from a student with a low one. we found that\\nlearning rate is significantly related to estimates of student ability\\n(prior knowledge) and self-reported measures of diligence.\\nfinally, we suggest a variety of possible applications of models\\nwith reliable estimates of individualized student parameters,\\nincluding a more novel, straightforward way of identifying wheel\\nspinning.\\n\\nkeywords\\nexplanatory models, model interpretability, individualized\\nparameters, 3, additive factors model, individualized bayesian\\nknowledge tracing\\n\\n1. ']\n",
      "['\\n\\nwe show how the novel use of a semantic representation\\nbased on osgood’s semantic differential scales can lead to\\neffective features in predicting short- and long-term learning\\nin students using a vocabulary learning system. previous\\nstudies in students’ intermediate knowledge states during\\nvocabulary acquisition did not provide much information\\non which semantic knowledge students gained during word\\nlearning practice. moreover, these studies relied on human\\nratings to evaluate the students’ responses. to solve this\\nproblem, we propose a semantic representation for words\\nbased on osgood’s semantic decomposition of vocabulary\\n[16]. to demonstrate our method can effectively represent\\nstudents’ knowledge in vocabulary acquisition, we build\\nmodels for predicting the student’s short-term vocabulary\\nacquisition and long-term retention. we compare the\\neffectiveness of our osgood-based semantic representation to\\nthat provided by word2vec neural word embedding [13], and\\nfind that prediction models using features based on osgood\\nscale-based scores (osg) perform better than the baseline\\nand are comparable in accuracy to those using word2vec\\nscore-based models (w2v). by using more interpretable\\nosgood-based scales, our study results can help with better\\nunderstanding of students’ ongoing learning states and\\ndesigning personalized learning systems that can address an\\nindividual’s weak points in vocabulary acquisition.\\n\\nkeywords\\n\\nvocabulary learning, semantic similarity, prediction model,\\nintelligent tutoring system\\n\\n1. ']\n",
      "['\\ngathering labeled data in educational data mining (edm)\\nis a time and cost intensive task. however, the amount\\nof available training data directly influences the quality of\\npredictive models. unlabeled data, on the other hand, is\\nreadily available in high volumes from intelligent tutoring\\nsystems and massive open online courses. in this paper, we\\npresent a semi-supervised classification pipeline that makes\\neffective use of this unlabeled data to significantly improve\\nmodel quality. we employ deep variational auto-encoders\\nto learn efficient feature embeddings that improve the performance for standard classifiers by up to 28% compared\\nto completely supervised training. further, we demonstrate\\non two independent data sets that our method outperforms\\nprevious methods for finding efficient feature embeddings\\nand generalizes better to imbalanced data sets compared\\nto expert features. our method is data independent and\\nclassifier-agnostic, and hence provides the ability to improve\\nperformance on a variety of classification tasks in edm.\\n\\nkeywords\\nsemi-supervised classification, variational auto-encoder, deep\\nneural networks, dimensionality reduction\\n\\n1.\\n\\n']\n"
     ]
    }
   ],
   "source": [
    "# 31) print your abstracts (they should contain a lot of \\n = carriage return)\n",
    "\n",
    "for i in df_concatenated.index:\n",
    "    print(df_concatenated['abstract'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 32) clean the abstract column using the \"apply\" function with a lambda\n",
    "# Hint: https://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.Series.apply.html\n",
    "\n",
    "df_concatenated['abstract'] = str(df_concatenated['abstract'])\n",
    "df_concatenated['abstract'] = df_concatenated['abstract'].apply(lambda x: x.rstrip('\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing documents using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 33) now we are going to do something a little more advanced:'\n",
    "# we are going to compute the similarity between two texts\n",
    "# using a method called tf-idf (we'll talk more about it later)\n",
    "# Hint: https://stackoverflow.com/questions/43631533/similarity-between-two-text-documents-in-python\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "34) What can you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35) repeat the same procedure with the entire papers\n",
    "# Use the same logic as the previous cell, but use the text_list variable that we defined previously\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 36) What are two documents that seem to be very similar?\n",
    "# print their abstract: \n",
    "# print the first 1000 characters of each paper. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 37) what seems to be similar between them? \n",
    "\n",
    "# they both talk about analyzing questions and answers from students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free exploration (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- try to extract the names of the author\n",
    "- find a way to get the top words shared across two texts\n",
    "- use a regex (or any other method) to get the list of references"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
